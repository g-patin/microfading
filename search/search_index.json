{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome !","text":"<p>Welcome on the documentation website of the microfading python package.</p> <p>This package aims to facilitate the manipulation of microfading data. Consequently, microfading data - provided by the users - play a central role in the package. Like in most analytical techniques, several microfading devices have been developed over the years. Each device produces its own specfic rawfiles that are usually very different from one device to another. To compare the results obtained with different devices, one solution is to convert each rawfile into a unique file format, which is the method that has been chosen in this package. </p> <p>This unique file format, called interim file, is simply an excel file with a specific inner structure to organize the data. Each excel file is composed of three sheets:</p> <ol> <li>info : contains the metadata related to the measurements, the object, and the project</li> <li>CIELAB : contains the colorimetric values</li> <li>spectra : contains the spectral values</li> </ol> <p>An exemple of an interim file can be found in the microfading package (get_datasets() function).</p> <p>The overall landscape of the package can be viewed as a tree or an hourglass shape. </p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"get_datasets/","title":"Get datasets","text":"In\u00a0[1]: Copied! <pre>import microfading as mf\n</pre> import microfading as mf In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[8]: Copied! <pre># by default rawfiles=False, BWS=True, stdev=False\nds = mf.get_datasets()\nds\n</pre> # by default rawfiles=False, BWS=True, stdev=False ds = mf.get_datasets() ds Out[8]: <pre>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0026.04_G02_BW3_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0025.04_G02_BW2_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0024.04_G02_BW1_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.yellowwood.01_G01_yellow_model_2024-08-01_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.vermillon.01_G01_red_model_2024-07-31_MFT1.xlsx')]</pre> In\u00a0[9]: Copied! <pre># retrieve all the rawfiles\nds = mf.get_datasets(rawfiles=True)\nds\n</pre> # retrieve all the rawfiles ds = mf.get_datasets(rawfiles=True) ds Out[9]: <pre>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.rfc'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01.rfc')]</pre> In\u00a0[10]: Copied! <pre># excluded the rawfiles performed on blue wool samples\nds = mf.get_datasets(rawfiles=True, BWS=False)\nds\n</pre> # excluded the rawfiles performed on blue wool samples ds = mf.get_datasets(rawfiles=True, BWS=False) ds Out[10]: <pre>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.rfc')]</pre> In\u00a0[11]: Copied! <pre># retrieved the interim files with standard devivation values\nds = mf.get_datasets(rawfiles=False, BWS=False, stdev=True)\nds\n</pre> # retrieved the interim files with standard devivation values ds = mf.get_datasets(rawfiles=False, BWS=False, stdev=True) ds Out[11]: <pre>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.dayflower4.G01_avg_0h_model_2024-07-30_MFT2.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.indigo3.G01_avg_0h_model_2024-08-02_MFT2.xlsx')]</pre>"},{"location":"get_datasets/","title":"Get datasets","text":"<pre><code>import microfading as mf\n</code></pre> <pre><code>\n</code></pre> <pre><code># by default rawfiles=False, BWS=True, stdev=False\nds = mf.get_datasets()\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0026.04_G02_BW3_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0025.04_G02_BW2_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0024.04_G02_BW1_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.yellowwood.01_G01_yellow_model_2024-08-01_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.vermillon.01_G01_red_model_2024-07-31_MFT1.xlsx')]\n</code></pre> <pre><code># retrieve all the rawfiles\nds = mf.get_datasets(rawfiles=True)\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.rfc'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01.rfc')]\n</code></pre> <pre><code># excluded the rawfiles performed on blue wool samples\nds = mf.get_datasets(rawfiles=True, BWS=False)\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.rfc')]\n</code></pre> <pre><code># retrieved the interim files with standard devivation values\nds = mf.get_datasets(rawfiles=False, BWS=False, stdev=True)\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.dayflower4.G01_avg_0h_model_2024-07-30_MFT2.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.indigo3.G01_avg_0h_model_2024-08-02_MFT2.xlsx')]\n</code></pre>"},{"location":"how-to-guides/","title":"How to guides","text":"<p>Another sentence in how to guides !!! Hello world.</p>"},{"location":"installation/","title":"Installation","text":"<p>To install the microfading package, open a terminal and enter the following line:</p> <pre><code>pip install microfading\n</code></pre>"},{"location":"references/","title":"References","text":""},{"location":"references/#commands","title":"Commands","text":""},{"location":"references/#datasets","title":"Datasets","text":"<ul> <li><code>get_datasets [rawfiles, BWS, stdev]</code> - Retrieve examples of data files.</li> </ul>"},{"location":"references/#databases-management","title":"Databases management","text":"<ul> <li><code>create_DB [folder]</code> - Create two empty databases (projects and objects).</li> <li><code>get_DB [db]</code> - Retrieve the databases.</li> <li><code>folder_DB</code> - Retrieve the folder where the databases are stored.</li> <li><code>add_new_project</code> - Add a new project to the database.</li> <li><code>add_new_object</code> - Add a new object to the database.</li> <li><code>update_DB_project [new, old]</code> - Modify or add a new parameter to the project database.</li> <li><code>update_DB_object [new, old]</code> - Modify or add a new parameter to the object database.</li> </ul>"},{"location":"references/#data-processing","title":"Data processing","text":"<ul> <li><code>process_rawdata [files, device]</code> - Process rawdata files into interim files.</li> </ul>"},{"location":"references/#mft-class","title":"MFT class","text":"<ul> <li><code>data_points</code> - Select colourimetric values for one or multiple light dose values.</li> </ul>"},{"location":"references/#microfading.microfading.MFT","title":"<code>MFT</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>src/microfading/microfading.py</code> <pre><code>class MFT(object):\n\n    def __init__(self, files:list, BWS:Optional[bool] = True, stdev:Optional[bool] = False) -&gt; None:\n        \"\"\"Instantiate a Microfading (MFT) class object in order to manipulate and visualize microfading analysis data.\n\n        Parameters\n        ----------\n        files : list\n            A list of string, where each string corresponds to the absolute path of text or csv file that contains the data and metadata of a single microfading measurement. The content of the file requires a specific structure, for which an example can be found in \"datasets\" folder of the microfading package folder (Use the get_datasets function to retrieve the precise location of such example files). If the file structure is not respected, the script will not be able to properly read the file and access its content.\n\n        BWS : bool, optional\n            When False, it ignores the measurements performed on BWS samples if included. \n\n        stdev: bool, optional\n            Indicate whether the input files contains standard deviation values, by default False\n        \"\"\"\n        self.files = files\n        self.BWS = BWS\n        self.stdev = stdev\n\n        if self.BWS == False:\n            self.files = [x for x in self.files if 'BW' not in x.name]\n\n\n\n\n\n    def __repr__(self) -&gt; str:\n        return f'Microfading data class - Number of files = {len(self.files)}'\n\n\n    def data_points(self, coordinates:Optional[list] = ['dE00'], dose_unit:Optional[str] = 'He', dose_values:Union[int, float, list, tuple] = 1, index:Optional[bool] = False):\n        \"\"\"Select colourimetric values for one or multiple light dose values.\n\n        Parameters\n        ----------\n        coordinates : Optional[list], optional\n            Select the desired colourimetric coordinates from the following list: ['L*', 'a*','b*', 'C*', 'h', 'dL*', 'da*','db*', 'dC*', 'dh', 'dE76', 'dE00', 'dR_vis'], by default ['dE00']\n\n        dose_unit : Optional[str], optional\n            Select the unit of the light energy, by default ['He']\n            Any of the following units can be added to the list: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)\n\n        dose_values : Union[int, float, list, tuple], optional\n            Select the values of the light energy, by default 1\n            A single value, a list of multiple values, or range values with a tuple (start, end, step) can be entered.\n\n        index : Optional[bool], optional\n            Whether to set the index of the returned dataframes, by default False\n\n        Returns\n        -------\n        A list of pandas dataframes\n            It returns the values of the wanted colour coordinates inside dataframes where each coordinate corresponds to a column.\n        \"\"\"\n\n        # Retrieve the range light dose values\n        doses = {'He':'He_MJ/m2', 'Hv':'Hv_Mlxh', 't': 't_sec'}\n\n        if isinstance(dose_values, (float, int)):\n            dose_values = [dose_values]\n\n        elif isinstance(dose_values, tuple):\n            dose_values = np.arange(dose_values[0], dose_values[1], dose_values[2])\n\n        elif isinstance(dose_values, list):\n            dose_values = dose_values        \n\n        # Retrieve the data\n        original_data = self.get_data(data='cl')\n\n        # Added the delta LabCh values to the data dataframes   \n        if original_data[0].columns.nlevels &gt; 1:\n\n            delta_coord = [unumpy.uarray(d[coord, 'mean'], d[coord, 'std']) - unumpy.uarray(d[coord, 'mean'], d[coord, 'std'])[0] for coord in ['L*', 'a*', 'b*', 'C*', 'h'] for d in original_data]\n\n            delta_means = [unumpy.nominal_values(x) for x in delta_coord]\n            delta_stds = [unumpy.std_devs(x) for x in delta_coord]\n\n            delta_coord_mean = [(f'd{coord}', 'mean') for coord in ['L*', 'a*', 'b*', 'C*', 'h']]\n            delta_coord_std = [(f'd{coord}', 'std') for coord in ['L*', 'a*', 'b*', 'C*', 'h']]\n\n            # Add the new columns to the dictionary\n            data = []\n\n            for d in original_data:\n                print(d)\n                for coord_mean,delta_mean,coord_std,delta_std in zip(delta_coord_mean,delta_means, delta_coord_std,delta_stds):\n                    print(coord_mean)\n                    print(len(delta_mean))\n                    d[coord_mean] = delta_mean\n                    d[coord_std] = delta_std\n\n                data.append(d)\n\n\n            # Select the wanted dose_unit and coordinate        \n            wanted_data = [x[[doses[dose_unit]] + coordinates] for x in data]        \n            wanted_data = [x.set_index(x.columns[0]) for x in wanted_data]\n\n        else:\n\n            data = [d.assign(**{f'd{coord}': d[coord] - d[coord].values[0] for coord in ['L*', 'a*', 'b*', 'C*', 'h']}) for d in original_data]\n\n            # Select the wanted dose_unit and coordinate        \n            wanted_data = [x[[doses[dose_unit]] + coordinates] for x in data]        \n            wanted_data = [x.set_index(x.columns[0]) for x in wanted_data]\n\n        # Interpolation function, assuming linear interpolation\n        interp_functions = lambda x, y: interp1d(x, y, kind='linear', bounds_error=False)\n\n        # Double comprehension list to interpolate each dataframe in wanted_data\n        interpolated_data = [\n            pd.DataFrame({\n                col: interp_functions(df.index, df[col])(dose_values)\n                for col in df.columns\n            }, index=dose_values)\n            .rename_axis(doses[dose_unit])\n            .reset_index()\n            for df in wanted_data\n        ]\n\n        # Whether to set the index\n        if index:\n            interpolated_data = [x.set_index(x.columns[0]) for x in interpolated_data]\n\n        return interpolated_data       \n\n\n    def delta(self, coordinates:Optional[list] = ['dE00'], dose_unit:Optional[list] = ['He'], rate:Optional[bool] = False):\n        \"\"\"Retrieve the CIE delta values for a given set of colorimetric coordinates corresponding to the given microfading analyses.\n\n        Parameters\n        ----------\n        coordinates : list, optional\n            List of colorimetric coordinates, by default ['dE00']\n            Any of the following coordinates can be added to the list: 'dE76', 'dE00', 'dR_vis' , 'L*', 'a*', 'b*', 'C*', 'h'.\n\n        dose_unit : list, optional\n            List of light energy doses, by default ['He']\n            Any of the following units can be added to the list: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)\n\n        rate : bool, optional\n            Whether to return the first derivative values of the desired coordinates, by default False\n\n        Returns\n        -------\n        _type_\n            Returns a Pandas dataframe where each column corresponds to a desired coordinate or light energy dose.\n        \"\"\"\n\n        doses_dic = {'He': 'He_MJ/m2', 'Hv': 'Hv_Mlxh', 't': 't_sec'} \n        doses_labels = [doses_dic[x] for x in dose_unit]\n\n        wanted_data = []\n\n\n        if self.stdev == False: \n\n            doses = self.get_data(data=doses_labels) \n            data = self.get_data(data=coordinates)        \n\n\n            for el_data,el_dose in zip(data,doses):\n                for col in el_data.columns:\n                    if col in ['L*','a*','b*','C*','h']:\n                        values = el_data[col]\n                        values_delta = values - values[0]   \n\n                        el_data[col] = values_delta\n                        el_data.rename(columns={col:f'd{col}'}, inplace=True)\n\n                if rate:   \n\n                    step_dose = el_dose.iloc[:,0].values[2]-el_dose.iloc[:,0].values[1]\n\n                    el_data = pd.DataFrame(np.gradient(el_data.T.values, step_dose, axis=1).T, columns=el_data.columns)\n\n                wanted_data.append(pd.concat([el_dose, el_data], axis=1))\n\n\n        else:\n\n            data = self.get_data(data=coordinates)[0] - self.get_data(data=coordinates)[0].iloc[0,:]\n            doses = self.get_data(data=doses_labels)\n            wanted_data = [pd.concat([doses[0],data], axis=1)]\n\n            new_columns = []\n            for i in wanted_data:\n                for col in i.columns:\n                    if col[1] in ['L*','a*','b*','C*','h']:\n                        new_columns.append((col[0], f'd{col[1]}'))\n                    else:\n                        new_columns.append(col)\n\n                i.columns = pd.MultiIndex.from_tuples(new_columns, names=i.columns.names)          \n\n\n        return wanted_data\n\n\n    def fit_data(self, plot:Optional[bool] = False, return_data:Optional[bool] = False, dose_unit:Optional[str] = 'He', coordinate:Optional[str] = 'dE00', equation:Optional[str] = 'c0*(x**c1)', initial_params:Optional[List[float]] = [0.1, 0.0], x_range:Optional[Tuple[int]] = (0, 1001, 1), save: Optional[bool] = False, path_fig: Optional[str] = 'default') -&gt; Union[None, Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"Fit the values of a given colourimetric coordinates. \n\n        Parameters\n        ----------\n        plot : bool, optional\n            Whether to show the fitted data, by default False\n\n        return_data : bool, optional\n            Whether to return the fitted data, by default False\n\n        dose_unit : string, optional\n            Select the light energy dose, by default 'He'\n            Any of the following units can be used: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)\n\n        coordinates : string, optional\n            Select the desired colourimetric coordinates from the following list: ['L*', 'a*','b*', 'C*', 'h', 'dL*', 'da*','db*', 'dC*', 'dh', 'dE76', 'dE00', 'dR_vis'], by default 'dE00'\n\n        equation : str, optional\n            Mathematical equation used to fit the coordinate values, by default 'c0*(x**c1)'\n\n        initial_params : Optional[List[float]], optional\n            Initial guesses of the 'c' parameters given in the equation (c0, c1, c2, etc.), by default [0.1, 0.0]\n\n        x_range : Optional[Tuple[int]], optional\n            Values along which the fitted values should be computed (start, end, step), by default (0, 1001, 1)\n\n        save : Optional[bool], optional\n            Whether to save the plot, by default False\n\n        path_fig : Optional[str], optional\n            Absolute path of the figure to be saved, by default 'default'\n\n        Returns\n        -------\n        Union[None, Tuple[np.ndarray, np.ndarray]]\n            _description_\n        \"\"\"\n\n        # Retrieve the range light dose values\n        doses = {'He':'He_MJ/m2', 'Hv':'Hv_Mlxh', 't': 't_sec'}  \n        x_values = np.arange(*x_range)\n\n        # Retrieve the data\n        original_data = self.get_data(data='cl')\n\n        #original_data = self.get_data(data='dE') if self.data_category == 'interim' else self.get_data(data='dE')[0].astype(float)\n\n        # Added the delta LabCh values to the data dataframes\n        coordinates = ['L*', 'a*', 'b*', 'C*', 'h']\n        data = [d.assign(**{f'd{coord}': d[coord] - d[coord].values[0] for coord in coordinates}) for d in original_data]\n\n        # Select the wanted dose_unit and coordinate\n        wanted_data = [x[[doses[dose_unit], coordinate]] for x in data]\n        wanted_data = [x.set_index(x.columns[0]) for x in wanted_data]\n\n        # Define the function to fit\n        def fit_function(x, *params):\n            param_dict = {f'c{i}': param for i, param in enumerate(params)}\n            param_dict['x'] = x\n            return eval(equation, globals(), param_dict)\n\n        # Define boundaries for the parameters\n        #bounds = ([-np.inf] * len(initial_params), [np.inf, 1]) if len(initial_params) == 2 else ([-np.inf] * len(initial_params), [np.inf, 1, np.inf])\n\n        # Create an empty dataframe for the fitted data\n        fitted_data = pd.DataFrame(index=pd.Series(x_values))\n\n        # Empty list to store the labels\n        fitted_labels = []\n\n        # Emtpy list to store the optimized parameters\n        fitted_parameters = []\n\n        for d in wanted_data:\n            # retrieve the x(light dose) and y(coordinate) values\n            x, y = d.index, d.iloc[:,0]\n\n            # perform the curve fitting\n            optimized_params, _ = curve_fit(fit_function, x, y, p0=initial_params, ) # bounds=bounds\n\n            # generate fitted y data\n            fitted_y = fit_function(x_values, *optimized_params)\n\n            # append it to the fitted_data dataframe\n            fitted_data = pd.concat([fitted_data, pd.DataFrame(fitted_y, index=pd.Series(x_values))], axis=1)\n\n            # Calculate R-squared value\n            residuals = y - fit_function(x, *optimized_params)\n            ss_res, ss_tot = np.sum(residuals**2), np.sum((y - np.mean(y))**2)        \n            r_squared = np.round(1 - (ss_res / ss_tot), 3)\n\n            # Create a string representation of the equation with optimized parameters\n            optimized_equation = equation\n            for i, param in enumerate(optimized_params):\n                optimized_equation = optimized_equation.replace(f'c{i}', str(np.round(param,2)))\n\n            fitted_labels.append(f'{optimized_equation}, $R^2$ = {r_squared}')\n            fitted_parameters.append(optimized_params)\n\n        fitted_data.columns = [f'{x.split(\".\")[-1]}, $y$ = {y}' for x,y in zip(self.meas_ids, fitted_labels)]         \n\n        if plot:\n            labels_eq = {\n                'L*': r'CIE $L^*$',\n                'a*': r'CIE $a^*$',\n                'b*': r'CIE $b^*$',\n                'C*': r'CIE $C^*$',\n                'h': r'CIE $h$',\n                'dE76': r'$\\Delta E^*_{ab}$',\n                'dE00': r'$\\Delta E^*_{00}$',\n                'dR_VIS': r'$\\Delta R_{\\rm vis}$',\n                'dL*': r'CIE $\\Delta L^*$',\n                'da*': r'CIE $\\Delta a^*$',\n                'db*': r'CIE $\\Delta b^*$',\n                'dC*': r'CIE $\\Delta C^*$',\n                'dh': r'CIE $\\Delta h$',\n            }\n\n            labels_H = {\n                'Hv': 'Exposure dose $H_v$ (Mlxh)',\n                'He': 'Radiant Exposure $H_e$ (MJ/m\u00b2)',\n                't' : 'Exposure duration (seconds)'\n            }\n\n            sns.set_theme(context='paper', font='serif', palette='colorblind')\n            fig, ax = plt.subplots(1,1, figsize=(10,6))\n            fs = 24\n\n\n            pd.concat(wanted_data, axis=1).plot(ax=ax, color='0.7', ls='-', lw=5, legend=False)\n            fitted_data.plot(ax=ax, lw=2, ls='--')\n\n            #meas_line, = ax.plot(x,y, ls='-', lw=3)            \n            #fitted_line, = ax.plot(x_values,fitted_y, ls='--', lw=2)\n\n            ax.set_xlabel(labels_H[dose_unit], fontsize=fs)\n            ax.set_ylabel(labels_eq[coordinate],fontsize=fs)\n\n            #title = f'Microfading, {self.Id}, data fitting'\n            #ax.set_title(title, fontsize = fs-4)   \n\n            '''\n            if coordinate.startswith('d'):                \n                ax.set_ylim(0) \n            '''\n\n            ax.set_xlim(0)    \n\n            ax.xaxis.set_tick_params(labelsize=fs)\n            ax.yaxis.set_tick_params(labelsize=fs)\n\n            #plt.legend([meas_line,fitted_line], [\"original data\",f\"$f(x) = {optimized_equation}$\\n$R^2 = {r_squared:.3f}$\"],fontsize=fs-6)\n            #plt.tight_layout()\n\n\n            if save:\n\n                filename = self.make_filename('dEfit')\n\n                if save:            \n                    if path_fig == 'default':\n                        path_fig = self.get_folder_figures() / filename\n\n                    if path_fig == 'cwd':\n                        path_fig = f'{os.getcwd()}/{filename}' \n\n                    plt.savefig(path_fig, dpi=300, facecolor='white')\n\n            plt.show()\n\n        if return_data:\n            return fitted_parameters, fitted_data\n\n\n    def read_files(self, sheets:Optional[list] = ['info', 'CIELAB', 'spectra']):\n        \"\"\"Read the data files given as argument when defining the instance of the MFT class.\n\n        Parameters\n        ----------\n        sheets : Optional[list], optional\n            Name of the excel sheets to be selected, by default ['info', 'CIELAB', 'spectra']\n\n        Returns\n        -------\n        pandas dataframe\n            It returns of the content of the files where the each column relates to a file.\n        \"\"\"\n\n        files = []        \n\n        for file in self.files:\n\n            df_info = pd.read_excel(file, sheet_name='info')\n            df_sp = pd.read_excel(file, sheet_name='spectra')\n            df_cl = pd.read_excel(file, sheet_name='CIELAB')\n\n            if 'std' in list(df_sp.iloc[0,:].values):\n                df_sp = pd.read_excel(file, sheet_name='spectra', header=[0,1], index_col=0)\n                df_cl = pd.read_excel(file, sheet_name='CIELAB', header=[0,1])\n\n\n            if sheets == ['info', 'CIELAB', 'spectra']:\n                files.append([df_info, df_cl, df_sp])\n\n            elif sheets == ['info']:\n                files.append([df_info])\n\n            elif sheets == ['CIELAB']:\n                files.append([df_cl])\n\n            elif sheets == ['spectra']:\n                files.append([df_sp])\n\n            elif sheets == ['spectra', 'CIELAB']:\n                files.append([df_sp, df_cl])\n\n            elif sheets == ['CIELAB','spectra']:\n                files.append([df_cl, df_sp])\n\n            elif sheets == ['info','CIELAB']:\n                files.append([df_info, df_cl])\n\n            elif sheets == ['info','spectra']:\n                files.append([df_info, df_sp])\n\n        return files\n\n\n    def get_data(self, data:Union[str, list] = 'all', xarray:Optional[bool] = False):\n        \"\"\"Retrieve the microfading data.\n\n        Parameters\n        ----------\n        data : str|list, optional\n            Possibility to select the type of data, by default 'all'.\n            When 'all', it returns all the data (spectral and colorimetric).\n            When 'sp', it only returns the spectral data.\n            When 'cl', it only returns the colorimetric data.  \n            When 'Lab', it returns the CIE L*a*b* values.\n            A list of strings can be entered to select specific colourimetric data among the following: ['dE76,'dE00','dR_vis', 'L*', 'a*', 'b*', 'C*', 'h'].\n\n        xarray : bool, optional\n            When True, the data are returned as an xarray.Dataset object, else as pandas dataframe object, by default False.\n\n        Returns\n        -------\n        returns a list of pandas dataframes or xarray.Dataset objects\n        \"\"\"\n\n        all_files = self.read_files(sheets=['spectra','CIELAB'])\n        all_data = []\n        data_sp = [] \n        data_cl = [] \n\n        for data_file in all_files:\n\n            sp = data_file[0].iloc[:,1:].values            \n            wl = data_file[0].iloc[:,0].values\n            He = data_file[1]['He_MJ/m2'].values\n            Hv = data_file[1]['Hv_Mlxh'].values\n            t = data_file[1]['t_sec'].values\n            L = data_file[1][\"L*\"].values\n            a = data_file[1][\"a*\"].values\n            b = data_file[1][\"b*\"].values\n            C = data_file[1][\"C*\"].values\n            h = data_file[1][\"h\"].values\n            dE76 = data_file[1][\"dE76\"].values\n            dE00 = data_file[1][\"dE00\"].values\n            dR_vis = data_file[1][\"dR_vis\"].values\n\n            spectral_data = xr.Dataset(\n                {\n                    'sp': (['wavelength','dose'], sp)                \n                },\n                coords={\n                    'wavelength': wl,   \n                    'dose': He,\n                    'He': ('dose', He),\n                    'Hv': ('dose', Hv),  # Match radiant energy\n                    't': ('dose', t)  # Match radiant energy\n                }\n            )\n\n            color_data = xr.Dataset(\n                {\n                    'L*': (['dose'], L),\n                    'a*': (['dose'], a),\n                    'b*': (['dose'], b),\n                    'C*': (['dose'], C),\n                    'h': (['dose'], h),\n                    'dE76': (['dose'], dE76),\n                    'dE00': (['dose'], dE00),\n                    'dR_vis': (['dose'], dR_vis),\n                },\n                coords={                    \n                    'He': ('dose',He),\n                    'Hv': ('dose',Hv),\n                    't': ('dose',t),\n                }\n            )                \n\n            sp = spectral_data.set_xindex([\"He\",\"Hv\",\"t\"])\n            cl = color_data.set_xindex([\"He\",\"Hv\",\"t\"])\n            combined_data = xr.merge([sp, cl])\n\n        all_data.append(combined_data)            \n\n\n        if data == 'all':\n            if xarray == False:\n                [data_sp.append(x[0]) for x in all_files]\n                [data_cl.append(x[1]) for x in all_files]\n                return data_sp, data_cl\n\n            else:\n                return all_data\n\n        elif data == 'sp':\n            if xarray == False:\n                [data_sp.append(x[0]) for x in all_files]                            \n            else:\n                data_sp = [x.sp for x in all_data]\n\n            return data_sp\n\n        elif data == 'cl':\n            if xarray == False:\n                [data_cl.append(x[1]) for x in all_files]\n            else:\n                data_cl = [x[['L*','a*','b*','C*','h','dE76','dE00','dR_vis']] for x in all_data]\n\n            return data_cl\n\n        elif data == 'Lab':\n            if xarray == False:\n                [data_cl.append(x[1][['L*','a*','b*']]) for x in all_files]\n            else:\n                data_cl = [x[['L*','a*','b*']] for x in all_data]\n\n            return data_cl\n\n        elif isinstance(data,list):\n            if xarray == False:\n                dic_doses = {'He': 'He_MJ/m2', 'Hv':'Hv_Mlxh', 't':'t_sec'}\n                data = [dic_doses[x] if x in dic_doses.keys() else x for x in data]\n                [data_cl.append(x[1][data]) for x in all_files]\n\n            else:\n                data = [elem for elem in data if elem not in ['Hv','He','t']]\n                data_cl = [x[data] for x in all_data]\n\n            return data_cl\n\n        else:\n            print(\"Enter a valid data parameter. It can either be a string ('sp', 'cl', 'Lab', 'all') or a list of strings ['dE00','dE76', 'L*', 'a*', 'b*', 'C*', 'h']\")\n            return None\n\n\n    def get_metadata(self, labels:Optional[list] = 'all'):\n        \"\"\"Retrieve the metadata.\n\n        Parameters\n        ----------\n        labels : Optional[list], optional\n            A list of strings corresponding to the wanted metadata labels, by default 'all'\n            The metadata labels can be found in the 'info' sheet of microfading excel files.\n            When 'all', it returns all the metadata\n\n        Returns\n        -------\n        pandas dataframe\n            It returns the metadata inside a pandas dataframe where each column corresponds to a single file.\n        \"\"\"\n\n        df = self.read_files()\n        metadata = [x[0] for x in df]\n\n        df_metadata = pd.DataFrame(index = metadata[0].set_index('parameter').index)\n\n        for m in metadata:\n            m = m.set_index('parameter')\n            Id = m.loc['meas_id']['value']\n\n            df_metadata[Id] = m['value']\n\n        if labels == 'all':\n            return df_metadata\n\n        else:            \n            return df_metadata.loc[labels]\n\n\n    def Lab(self, illuminant:Optional[str] = 'D65', observer:Optional[str] = '10'):\n        \"\"\"\n        Retrieve the CIE L*a*b* values.\n\n        Parameters\n        ----------\n        illuminant : (str, optional)  \n            Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n        observer : (str|int, optional)\n            Reference *observer* in degree ('10' or '2'). by default '10'.\n\n\n        Returns\n        -------\n        pandas dataframe\n            It returns the L*a*b* values inside a dataframe where each column corresponds to a single file.\n        \"\"\"        \n        observer = str(observer)\n\n        illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n        observers = {\n            '10': 'cie_10_1964',\n            '2' : 'cie_2_1931',\n        }\n        cmfs_observers = {\n            '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n            '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n            }\n\n        ccs_ill = colour.CCS_ILLUMINANTS[observers[observer]][illuminant]\n\n        meas_ids = self.meas_ids\n\n        if self.stdev:\n            df_sp = [x['mean'] for x in self.get_data(data='sp')]\n        else:\n            df_sp = self.get_data(data='sp')\n\n        df_Lab = []\n\n\n        for df, meas_id in zip(df_sp, meas_ids):            \n            Lab_values = pd.DataFrame(index=['L*','a*','b*']).T           \n\n            for col in df.columns:\n\n                sp = df[col]\n                wl = df.index\n                sd = colour.SpectralDistribution(sp,wl)                \n\n                XYZ = colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant])        \n                Lab = np.round(colour.XYZ_to_Lab(XYZ/100,ccs_ill),2)               \n                Lab_values = pd.concat([Lab_values, pd.DataFrame(Lab, index=['L*','a*','b*']).T], axis=0)\n                Lab_values.index = np.arange(0,Lab_values.shape[0])\n\n            Lab_values.columns = pd.MultiIndex.from_product([[meas_id], Lab_values.columns])\n            df_Lab.append(Lab_values)\n\n        return pd.concat(df_Lab, axis=1)\n\n\n    @property\n    def meas_ids(self):\n        \"\"\"Return the measurement id numbers corresponding to the input files.\n        \"\"\"\n        info = self.get_metadata()        \n        return info.loc['meas_id'].values\n\n\n    def mean(self, return_data:Optional[bool] = True, criterion:Optional[str] = 'group', save:Optional[bool] = False, folder:Optional[str] = 'default', filename:Optional[str] = 'default'):\n        \"\"\"Compute mean and standard deviation values of several microfading measurements.\n\n        Parameters\n        ----------\n        return_data : Optional[bool], optional\n            Whether to return the data, by default True        \n\n        criterion : Optional[str], optional\n            _description_, by default 'group'            \n\n        save : Optional[bool], optional\n            Whether to save the average data as an excel file, by default False\n\n        folder : Optional[str], optional\n            Folder where the excel file will be saved, by default 'default'\n            When 'default', the file will be saved in the same folder as the input files\n            When '.', the file will be saved in the current working directory\n            One can also enter a valid path as a string.\n\n        filename : Optional[str], optional\n            Filename of the excel file containing the average values, by default 'default'\n            When 'default', it will use the filename of the first input file\n            One can also enter a filename, but without a filename extension.\n\n        Returns\n        -------\n        tuple, excel file\n            It returns a tuple composed of three elements (info, CIELAB data, spectral data). When 'save' is set to True, an excel is created to stored the tuple inside three distinct excel sheet (info, CIELAB, spectra).\n\n        Raises\n        ------\n        RuntimeError\n            _description_\n        \"\"\"\n\n        if len(self.files) &lt; 2:        \n            raise RuntimeError('Not enough files. At least two measurement files are required to compute the average values.')\n\n\n        def mean_std_with_nan(arrays):\n            '''Compute the mean of several numpy arrays of different shapes.'''\n\n            # Find the maximum shape\n            max_shape = np.max([arr.shape for arr in arrays], axis=0)\n\n            # Create arrays with NaN values\n            nan_arrays = [np.full(max_shape, np.nan) for _ in range(len(arrays))]\n\n            # Fill NaN arrays with actual values\n            for i, arr in enumerate(arrays):\n                nan_arrays[i][:arr.shape[0], :arr.shape[1]] = arr\n\n            # Calculate mean\n            mean_array = np.nanmean(np.stack(nan_arrays), axis=0)\n\n            # Calculate std\n            std_array = np.nanstd(np.stack(nan_arrays), axis=0)\n\n            return mean_array, std_array\n\n\n        def to_float(x):\n            try:\n                return float(x)\n            except ValueError:\n                return x\n\n\n        ###### SPECTRAL DATA #######\n\n        data_sp = self.get_data(data='sp')\n\n        # Get the energy dose step\n        H_values = [x.columns.astype(float) for x in data_sp]       \n        step_H = sorted(set([x[2] - x[1] for x in H_values]))[0]\n        highest_He = np.max([x[-1] for x in H_values])\n\n        # Average the spectral data\n        sp = mean_std_with_nan(data_sp)\n        sp_mean = sp[0]\n        sp_std = sp[1] \n\n\n        # Wanted energy dose values          \n        wanted_H = np.round(np.arange(0,highest_He+step_H,step_H),1)  \n\n        if len(wanted_H) != sp_mean.shape[1]:            \n            wanted_H = np.linspace(0,highest_He,sp_mean.shape[1])\n\n        # Retrieve the wavelength range\n        wl = self.wavelength.iloc[:,0]\n\n\n        # Create a multi-index pandas DataFrame\n        H_tuples = [(dose, measurement) for dose in wanted_H for measurement in ['mean', 'std']]\n        multiindex_cols = pd.MultiIndex.from_tuples(H_tuples, names=['He_MJ/m2', 'Measurement'])\n\n        data_df_sp = np.empty((len(wl), len(wanted_H) * 2))       \n        data_df_sp[:, 0::2] = sp_mean\n        data_df_sp[:, 1::2] = sp_std\n        df_sp_final = pd.DataFrame(data_df_sp,columns=multiindex_cols, index=wl)\n        df_sp_final.index.name = 'wavelength_nm'\n\n\n\n        ###### COLORIMETRIC DATA #######\n\n        data_cl = self.get_data(data='dE')\n        columns_cl = data_cl[0].columns\n\n        # Average the colorimetric data    \n        cl = mean_std_with_nan(data_cl)\n        cl_mean = cl[0]\n        cl_std = cl[1]\n\n        # Create a multi-index pandas DataFrame\n        cl_tuples = [(x, measurement) for x in data_cl[0].columns for measurement in ['mean', 'std']]\n        multiindex_cols = pd.MultiIndex.from_tuples(cl_tuples, names=['coordinates', 'Measurement'])\n\n        data_df_cl = np.empty((cl_mean.shape[0], cl_mean.shape[1] * 2))       \n        data_df_cl[:, 0::2] = cl_mean\n        data_df_cl[:, 1::2] = cl_std\n        df_cl_final = pd.DataFrame(data_df_cl,columns=multiindex_cols, )\n        df_cl_final.drop([('He_MJ/m2','std'), ('Hv_Mlxh','std'), ('t_sec','std')], axis=1, inplace=True)\n\n        mapper = {('He_MJ/m2', 'mean'): ('He_MJ/m2', 'value'), ('Hv_Mlxh', 'mean'): ('Hv_Mlxh', 'value'), ('t_sec', 'mean'): ('t_sec', 'value')}\n        df_cl_final.columns = pd.MultiIndex.from_tuples([mapper.get(x, x) for x in df_cl_final.columns])\n\n\n        cl_cols = df_cl_final.columns\n        cl_cols_level1 = [x[0] for x in cl_cols]\n        cl_cols_level2 = [x[1] for x in cl_cols]\n        df_cl_final.columns = np.arange(0,df_cl_final.shape[1])\n\n        df_cl_final = pd.concat([pd.DataFrame(data=np.array([cl_cols_level2])), df_cl_final])\n        df_cl_final.columns = cl_cols_level1\n        df_cl_final = df_cl_final.set_index(df_cl_final.columns[0])\n\n\n        ###### INFO #######\n\n        data_info = self.get_metadata().fillna(' ')\n\n        # Select the first column as a template\n        df_info = data_info.iloc[:,0]\n\n\n        # Rename title file\n        df_info.rename({'[SINGLE MICRO-FADING ANALYSIS]': '[MEAN MICRO-FADING ANALYSES]'}, inplace=True)\n\n        # Date time\n        most_recent_dt = max(data_info.loc['date_time'])\n        df_info.loc['date_time'] = most_recent_dt\n\n        # Project data info\n        df_info.loc['project_id'] = '_'.join(sorted(set(data_info.loc['project_id'].values)))\n        df_info.loc['projectleider'] = '_'.join(sorted(set(data_info.loc['projectleider'].values)))\n        df_info.loc['meelezer'] = '_'.join(sorted(set(data_info.loc['meelezer'].values)))\n        df_info.loc['aanvraagdatum'] = '_'.join(sorted(set(data_info.loc['aanvraagdatum'].values)))\n        df_info.loc['uiterste_datum'] = '_'.join(sorted(set(data_info.loc['uiterste_datum'].values)))\n\n        # Object data info\n        if len(set([x.split('_')[0] for x in data_info.loc['institution'].values])) &gt; 1:\n            df_info.loc['institution'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['institution'].values])))\n\n        df_info.loc['object_id'] = '_'.join(sorted(set(data_info.loc['object_id'].values)))\n        df_info.loc['object_category'] = '_'.join(sorted(set(data_info.loc['object_category'].values)))\n        df_info.loc['object_type'] = '_'.join(sorted(set(data_info.loc['object_type'].values)))\n        df_info.loc['object_technique'] = '_'.join(sorted(set(data_info.loc['object_technique'].values)))\n        df_info.loc['object_title'] = '_'.join(sorted(set(data_info.loc['object_title'].values)))\n        df_info.loc['object_name'] = '_'.join(sorted(set(data_info.loc['object_name'].values)))\n        df_info.loc['object_creator'] = '_'.join(sorted(set(data_info.loc['object_creator'].values)))\n        df_info.loc['object_date'] = '_'.join(sorted(set(data_info.loc['object_date'].values)))\n        df_info.loc['object_support'] = '_'.join(sorted(set(data_info.loc['object_support'].values)))\n        df_info.loc['color'] = '_'.join(sorted(set(data_info.loc['color'].values)))\n        df_info.loc['colorants'] = '_'.join(sorted(set(data_info.loc['colorants'].values)))\n        df_info.loc['colorants_name'] = '_'.join(sorted(set(data_info.loc['colorants_name'].values)))\n        df_info.loc['binding'] = '_'.join(sorted(set(data_info.loc['binding'].values)))\n        df_info.loc['ratio'] = '_'.join(sorted(set(data_info.loc['ratio'].values)))\n        df_info.loc['thickness_microns'] = '_'.join(sorted(set(data_info.loc['thickness_microns'].values)))\n        df_info.loc['status'] = '_'.join(sorted(set(data_info.loc['status'].values)))\n\n        # Device data info\n        if len(set(data_info.loc['device'].values)) &gt; 1:\n            df_info.loc['device'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['device'].values])))\n\n        df_info.loc['measurement_mode'] = '_'.join(sorted(set(data_info.loc['measurement_mode'].values)))\n        df_info.loc['zoom'] = '_'.join(sorted(set(data_info.loc['zoom'].values)))\n        df_info.loc['iris'] = '_'.join(sorted(set(str(data_info.loc['iris'].values))))\n        df_info.loc['geometry'] = '_'.join(sorted(set(data_info.loc['geometry'].values)))\n        df_info.loc['distance_ill_mm'] = '_'.join(sorted(set(str(data_info.loc['distance_ill_mm'].values))))\n        df_info.loc['distance_coll_mm'] = '_'.join(sorted(set(str(data_info.loc['distance_coll_mm'].values))))       \n\n        if len(set(data_info.loc['fiber_fading'].values)) &gt; 1:\n            df_info.loc['fiber_fading'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['fiber_fading'].values])))\n\n        if len(set(data_info.loc['fiber_ill'].values)) &gt; 1:\n            df_info.loc['fiber_ill'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['fiber_ill'].values])))\n\n        if len(set(data_info.loc['fiber_coll'].values)) &gt; 1:\n            df_info.loc['fiber_coll'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['fiber_coll'].values])))\n\n        if len(set(data_info.loc['lamp_fading'].values)) &gt; 1:\n            df_info.loc['lamp_fading'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['lamp_fading'].values])))\n\n        if len(set(data_info.loc['lamp_ill'].values)) &gt; 1:\n            df_info.loc['lamp_ill'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['lamp_ill'].values])))\n\n        if len(set(data_info.loc['filter_fading'].values)) &gt; 1:\n            df_info.loc['filter_fading'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['filter_fading'].values])))\n\n        if len(set(data_info.loc['filter_ill'].values)) &gt; 1:\n            df_info.loc['filter_ill'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['filter_ill'].values])))\n\n        if len(set(data_info.loc['white_ref'].values)) &gt; 1:\n            df_info.loc['white_ref'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['white_ref'].values])))\n\n\n        # Analysis data info\n\n        criterion_value = df_info.loc[criterion]\n        object_id = df_info.loc['object_id']\n        if criterion == 'group':            \n            df_info.loc['meas_id'] = f'MF.{object_id}.{criterion_value}'\n        elif criterion == 'object' or criterion == 'project':\n             df_info.loc['meas_id'] = f'MF.{criterion_value}'\n        else:\n            print('Choose one of the following options for the criterion parameter: [\"group\", \"object\", \"project\"]')\n\n        meas_nbs = '-'.join([x.split('.')[-1] for x in self.meas_ids])\n        df_info.loc['group'] = f'{\"-\".join(sorted(set(data_info.loc[\"group\"].values)))}_{meas_nbs}'    \n        df_info.loc['group_description'] = '_'.join(sorted(set(data_info.loc['group_description'].values)))\n        df_info.loc['background'] = '_'.join(sorted(set(data_info.loc['background'].values)))  \n\n        if len(set(data_info.loc['specular_component'].values)) &gt; 1:\n            df_info.loc['specular_component'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['specular_component'].values]))) \n\n\n        df_info.loc['integration_time_ms'] = np.round(np.mean(data_info.loc['integration_time_ms'].astype(float).values),1)\n        df_info.loc['average'] = '_'.join([str(x) for x in sorted(set(data_info.loc['average'].astype(str).values))]) \n        df_info.loc['duration_min'] = np.round(np.mean(data_info.loc['duration_min'].values),1)\n        df_info.loc['interval_sec'] = '_'.join([str(x) for x in sorted(set(data_info.loc['interval_sec'].values))])\n        df_info.loc['measurements_N'] = '_'.join([str(x) for x in sorted(set(data_info.loc['measurements_N'].astype(str).values))])\n        df_info.loc['illuminant'] = '_'.join(sorted(set(data_info.loc['illuminant'].values)))\n        df_info.loc['observer'] = '_'.join(sorted(set(data_info.loc['observer'].values)))\n\n\n        # Beam data info\n\n        df_info.loc['beam_photo'] = '_'.join(sorted(set(data_info.loc['beam_photo'].values)))\n        df_info.loc['resolution_micron/pixel'] = '_'.join(sorted(set(str(data_info.loc['resolution_micron/pixel'].values))))\n\n        fwhm = data_info.loc['FWHM_micron']\n        fwhm_avg = np.mean([i for i in [to_float(x) for x in fwhm] if isinstance(i, (int, float))])\n        df_info.loc['FWHM_micron'] = fwhm_avg\n\n        power_info = data_info.loc['power_mW']\n        power_avg = np.mean([ufloat_fromstr(x.split('_')[1]) for x in power_info])\n        power_ids = '-'.join(sorted(set([x.split('_')[0] for x in power_info])))\n        df_info.loc['power_mW'] = f'{power_ids}_{power_avg}' \n\n        irr_values = [str(ufloat(x,0)) if isinstance(x, int) else x for x in data_info.loc['irradiance_W/m**2'] ] \n        irr_mean = np.int32(np.mean([unumpy.nominal_values(ufloat_fromstr(x)) for x in irr_values]))\n        irr_std = np.int32(np.std([unumpy.nominal_values(ufloat_fromstr(x)) for x in irr_values]))\n        irr_avg = ufloat(irr_mean, irr_std)    \n        df_info.loc['irradiance_W/m**2'] = irr_avg\n\n        lm = [x for x in data_info.loc['luminuous_flux_lm'].values]\n        lm_avg = np.round(np.mean(lm),3)\n        df_info.loc['luminuous_flux_lm'] = lm_avg\n\n        ill = [x for x in data_info.loc['illuminance_Mlx']]\n        ill_avg = np.round(np.mean(ill),3)\n        df_info.loc['illuminance_Mlx'] = ill_avg\n\n\n        # Results data info\n        df_info.loc['totalDose_He_MJ/m**2'] = df_cl_final.index.values[-1]\n        df_info.loc['totalDose_Hv_Mlxh'] = df_cl_final['Hv_Mlxh'].values[-1]\n        df_info.loc['fittedEqHe_dE00'] = ''\n        df_info.loc['fittedEqHv_dE00'] = ''\n        df_info.loc['fittedRate_dE00_at_2Mlxh'] = ''\n        df_info.loc['fittedRate_dE00_at_20MJ/m**2'] = ''\n        df_info.loc['dE00_at_300klxh'] = ''\n        df_info.loc['dE00_at_3MJ/m**2'] = ''\n        df_info.loc['dEab_final'] = ufloat(df_cl_final['dE76'].values[-1][0], df_cl_final['dE76'].values[-1][1])\n        df_info.loc['dE00_final'] = ufloat(df_cl_final['dE00'].values[-1][0], df_cl_final['dE00'].values[-1][1])\n        df_info.loc['dR_VIS_final'] = ufloat(df_cl_final['dR_vis'].values[-1][0], df_cl_final['dR_vis'].values[-1][1])\n        df_info.loc['Hv_at_1dE00'] = ''\n        df_info.loc['BWSE'] = ''\n\n        # Rename the column\n        df_info.name = 'value'\n\n\n        ###### SAVE THE MEAN DATAFRAMES #######\n\n        if save:  \n\n            # set the folder\n            if folder == \".\":\n                folder = Path('.')  \n\n            elif folder == 'default':\n                folder = Path(self.files[0]).parent\n\n            else:\n                if Path(folder).exists():\n                    folder = Path(folder)         \n\n            # set the filename\n            if filename == 'default':\n                filename = f'{Path(self.files[0]).stem}_MEAN{Path(self.files[0]).suffix}'\n\n            else:\n                filename = f'{filename}.xlsx'\n\n\n            # create a excel writer object\n            with pd.ExcelWriter(folder / filename) as writer:\n\n                df_info.to_excel(writer, sheet_name='info', index=True)\n                df_cl_final.to_excel(writer, sheet_name=\"CIELAB\", index=True)\n                df_sp_final.to_excel(writer, sheet_name='spectra', index=True)\n\n\n        ###### RETURN THE MEAN DATAFRAMES #######\n\n        if return_data:\n            return df_info, df_cl_final, df_sp_final\n\n\n    def plot_sp(self, stds=[], spectra:Optional[str] = 'i', labels:Union[str,list] = 'default', title:Optional[str] = None, fontsize:Optional[int] = 24, fontsize_legend:Optional[int] = 26, wl_range:Optional[tuple] = None, colors:Union[str,list] = None, lw:Union[int, list] = 2, ls:Union[str, list] = '-', save=False, path_fig='cwd', derivation=False, smooth=False, smooth_params=[10,1], report:Optional[bool] = False):\n        \"\"\"Plot the reflectance spectra corresponding to the associated microfading analyses.\n\n        Parameters\n        ----------\n        stds : list, optional\n             A list of standard variation values respective to each element given in the data parameter, by default []\n\n        spectra : Optional[str], optional\n            Define which spectra to display, by default 'i'\n            Use 'i' for initial spectral, 'f' for final spectra, 'i+f' for initial and final spectra, or 'all' for all the spectra.\n\n        labels : Union[str, list], optional\n            _description_, by default 'default'\n\n        title : str, optional\n            Whether to add a title to the plot, by default None\n\n        fontsize : int, optional\n            Fontsize of the plot (title, ticks, and labels), by default 24\n\n        fontsize_legend : int, optional\n            Fontsize of the legend, by default 26\n\n        wl_range : tuple, optional\n            Define the wavelength range, by default None\n\n        colors : Union[str, list], optional\n            Define the colors of the reflectance curves, by default None\n            When 'sample', the color of each line will be based on srgb values computed from the reflectance values. Alternatively, a single string value can be used to define the color (see matplotlib colour values) or a list of matplotlib colour values can be used. \n\n        lw : Union[int, list], optional\n            Define the width of the plot lines, by default 2\n            It can be a single integer value that will apply to all the curves. Or a list of integers can be used where the number of integer elements should match the number of reflectance curves.\n\n        ls : Union[str, list], optional\n            Define the line style of the plot lines, by default '-'\n            It can be a string ('-', '--', ':', '-.') that will apply to all the curves. Or a list of string can be used where the number of string elements should match the number of reflectance curves.\n\n        save : bool, optional\n            Whether to save the figure, by default False\n\n        path_fig : str, optional\n            Absolute path required to save the figure, by default 'cwd'\n            When 'cwd', it will save the figure in the current working directory.\n\n        derivation : bool, optional\n            Wether to compute and display the first derivative values of the spectra, by default False\n\n        smooth : bool, optional\n            Whether to smooth the reflectance curves, by default False\n\n        smooth_params : list, optional\n            Parameters related to the Savitzky-Golay filter, by default [10,1]\n            Enter a list of two integers where the first value corresponds to the window_length and the second to the polyorder value. \n\n        report : Optional[bool], optional\n            _description_, by default False\n\n        Returns\n        -------\n        _type_\n            _description_\n        \"\"\"\n\n        # Retrieve the data\n        data_sp = self.get_data(data='sp')\n        data_sp = [x.set_index(x.columns[0]) for x in data_sp]\n        indices = [x.index for x in data_sp]        \n        columns = [x.columns for x in data_sp] \n\n\n        # Whether to smooth the data\n        if smooth:\n                data_sp = [pd.DataFrame(savgol_filter(x.T, window_length=smooth_params[0], polyorder=smooth_params[1]).T, index=idx, columns=cols) for x,idx,cols in zip(data_sp,indices,columns)]       \n\n        # Reset the index\n        data = [x.reset_index() for x in data_sp]\n\n        # Whether to compute the first derivative\n        if derivation:\n            data = [pd.concat([x.iloc[:,0], pd.DataFrame(np.gradient(x.iloc[:,1:], axis=0))], axis=1) for x in data]\n\n        # Retrieve the metadata\n        info = self.get_metadata()\n        object_info = info.loc['object_type'].values[0]\n        object_technique = info.loc['object_technique'][0]\n        group_nb = info.loc['group'].values[0]\n        group_descriptions = info.loc['group_description'].values\n        group_description = group_descriptions[0]\n\n        ids = [x for x in self.meas_ids if 'BW' not in x]\n        meas_nbs = [x.split('.')[-1] for x in ids]\n\n        # Select which spectra to plot \n        if spectra == 'i':\n            data = [(x.iloc[:,0].values, x.iloc[:,1].values) for x in data]            \n            text = 'Initial spectra'\n\n        elif spectra == 'f':\n            data = [(x.iloc[:,0].values, x.iloc[:,-1].values) for x in data]             \n            text = 'Final spectra'          \n\n        elif spectra == \"i+f\":\n            list_data = [[(x.iloc[:,0].values, x.iloc[:,1].values),(x.iloc[:,0].values, x.iloc[:,-1].values)] for x in data]\n            data = []\n\n            for l1 in list_data:\n                for l2 in l1:\n                    data.append(l2)\n\n            ls = ['--', '-'] * len(data)\n            lw = [2,3] * len(data)\n            colors = ['k',colors] * len(data)\n\n            meas_labels = [f'{x}-{y}' for x,y in zip(meas_nbs,group_descriptions)]\n            none_labels = [None] * len(meas_labels)\n            labels = [item for pair in zip(none_labels, meas_labels) for item in pair]\n            text = 'Initial (black dashed lines) and final spectra'\n\n        elif spectra == 'all' :\n\n            data = [\n                [(df.index.values, df[col].values) for col in df.columns]\n                for df in data_sp\n            ]\n            #data = [(x.iloc[:,0].values, x.iloc[:,1:].values) for x in data]            \n            labels = []\n            text = 'All spectra'\n            colors = None\n\n\n        return plotting.spectra(data, stds=[], labels=labels, title=title, fontsize=fontsize, fontsize_legend=fontsize_legend, x_range=wl_range, colors=colors, lw=lw, ls=ls, text=text, save=save, path_fig=path_fig, derivation=derivation)\n\n\n\n    def set_illuminant(self, illuminant:Optional[str] = 'D65', observer:Optional[str] = '10'):\n        \"\"\"Set the illuminant values.\n\n        Parameters\n        ----------\n        illuminant : Optional[str], optional\n            Select the illuminant, by default 'D65'\n            It can be any value within the following list: ['A', 'B', 'C', 'D50', 'D55', 'D60', 'D65', 'D75', 'E', 'FL1', 'FL2', 'FL3', 'FL4', 'FL5', 'FL6', 'FL7', 'FL8', 'FL9', 'FL10', 'FL11', 'FL12', 'FL3.1', 'FL3.2', 'FL3.3', 'FL3.4', 'FL3.5', 'FL3.6', 'FL3.7', 'FL3.8', 'FL3.9', 'FL3.10', 'FL3.11', 'FL3.12', 'FL3.13', 'FL3.14', 'FL3.15', 'HP1', 'HP2', 'HP3', 'HP4', 'HP5', 'LED-B1', 'LED-B2', 'LED-B3', 'LED-B4', 'LED-B5', 'LED-BH1', 'LED-RGB1', 'LED-V1', 'LED-V2', 'ID65', 'ID50', 'ISO 7589 Photographic Daylight', 'ISO 7589 Sensitometric Daylight', 'ISO 7589 Studio Tungsten', 'ISO 7589 Sensitometric Studio Tungsten', 'ISO 7589 Photoflood', 'ISO 7589 Sensitometric Photoflood', 'ISO 7589 Sensitometric Printer']\n\n        observer : Optional[str], optional\n            Standard observer in degree, by default '10'\n            It can be either '2' or '10'\n\n        Returns\n        -------\n        tuple\n            It returns a tuple with two set of values: the chromaticity coordinates of the illuminants (CCS) and the spectral distribution of the illuminants (SDS).\n        \"\"\"\n\n        observers = {\n            '10': \"cie_10_1964\",\n            '2' : \"cie_2_1931\"\n        }\n\n        CCS = colour.CCS_ILLUMINANTS[observers[observer]][illuminant]\n        SDS = colour.SDS_ILLUMINANTS[illuminant]\n\n        return CCS, SDS\n\n\n    def set_observer(self, observer:Optional[str] = '10'):\n        \"\"\"Set the observer.\n\n        Parameters\n        ----------\n        observer : Optional[str], optional\n            Standard observer in degree, by default '10'\n            It can be either '2' or '10'\n\n        Returns\n        -------        \n            Returns the x_bar,  y_bar, z_bar spectra between 360 and 830 nm.\n        \"\"\"\n\n        observers = {\n            '10': \"CIE 1964 10 Degree Standard Observer\",\n            '2' : \"CIE 1931 2 Degree Standard Observer\"\n        }\n\n        return colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[observers[observer]]\n\n\n    def sp_derivation(self):\n        \"\"\"Compute the first derivative values of reflectance spectra.\n\n        Returns\n        -------\n        a list of pandas dataframes\n            It returns the first derivative values of the reflectance spectra inside dataframes where each column corresponds to a single spectra.\n        \"\"\"\n\n        sp = self.get_data(data='sp')                    \n\n        sp_derivation = [pd.DataFrame(pd.concat([pd.DataFrame(np.gradient(x.iloc[:,:], axis=0), index=pd.Series(x.index), columns=x.columns)], axis=1),index=pd.Series(x.index), columns=x.columns) for x in sp]\n\n        return sp_derivation\n\n\n    def sRGB(self, illuminant='D65', observer='10'):\n        \"\"\"Compute the sRGB values. \n\n        Parameters\n        ----------\n        illuminant : (str, optional)  \n            Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n        observer : (str|int, optional)\n            Reference *observer* in degree ('10' or '2'). by default '10'.\n\n        Returns\n        -------\n        pandas dataframe\n            It returns the sRGB values inside a dataframe where each column corresponds to a single file.\n        \"\"\"\n        observer = str(observer)\n\n        illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n        observers = {\n            '10': 'cie_10_1964',\n            '2' : 'cie_2_1931',\n        }\n        cmfs_observers = {\n            '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n            '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n            }\n\n        ccs_ill = colour.CCS_ILLUMINANTS[observers[observer]][illuminant]\n\n        meas_ids = self.meas_ids                \n        df_sp = self.get_data(data='sp')       \n        df_srgb = []\n\n\n        for df, meas_id in zip(df_sp, meas_ids):\n\n            srgb_values = pd.DataFrame(index=['R','G','B']).T           \n\n            for col in df.columns:\n\n                sp = df[col]\n                wl = df.index\n                sd = colour.SpectralDistribution(sp,wl)                \n\n                XYZ = colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]) \n                srgb = colour.XYZ_to_sRGB(XYZ / 100, illuminant=ccs_ill)                          \n                srgb_values = pd.concat([srgb_values, pd.DataFrame(srgb, index=['R','G','B']).T], axis=0)\n                srgb_values.index = np.arange(0,srgb_values.shape[0])\n\n            srgb_values.columns = pd.MultiIndex.from_product([[meas_id], srgb_values.columns])\n            df_srgb.append(srgb_values)\n\n        return pd.concat(df_srgb, axis=1)\n\n\n    @property\n    def wavelength(self):\n        \"\"\"Return the wavelength range of the microfading measurements.\n        \"\"\"\n        data = self.get_data(data='sp')\n\n        wavelengths = pd.concat([pd.Series(x.index.values) for x in data], axis=1)\n        wavelengths.columns = self.meas_ids\n\n        return wavelengths\n\n\n    def XYZ(self, illuminant:Optional[str] = 'D65', observer:Union[str,int] = '10'):\n        \"\"\"Compute the XYZ values. \n\n        Parameters\n        ----------\n        illuminant : (str, optional)  \n            Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n        observer : (str|int, optional)\n            Reference *observer* in degree ('10' or '2'). by default '10'.\n\n        Returns\n        -------\n        pandas dataframe\n            It returns the XYZ values inside a dataframe where each column corresponds to a single file.\n        \"\"\"\n\n        observer = str(observer)\n\n        illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n\n        cmfs_observers = {\n            '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n            '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n            }\n\n        meas_ids = self.meas_ids                \n        df_sp = self.get_data(data='sp')       \n        df_XYZ = []\n\n\n        for df, meas_id in zip(df_sp, meas_ids):\n\n            XYZ_values = pd.DataFrame(index=['X','Y','Z']).T           \n\n            for col in df.columns:\n\n                sp = df[col]\n                wl = df.index\n                sd = colour.SpectralDistribution(sp,wl)                \n\n                XYZ = np.round(colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]),3)\n                XYZ_values = pd.concat([XYZ_values, pd.DataFrame(XYZ, index=['X','Y','Z']).T], axis=0)\n                XYZ_values.index = np.arange(0,XYZ_values.shape[0])\n\n            XYZ_values.columns = pd.MultiIndex.from_product([[meas_id], XYZ_values.columns])\n            df_XYZ.append(XYZ_values)\n\n        return pd.concat(df_XYZ, axis=1)\n\n\n    def xy(self, illuminant:Optional[str] = 'D65', observer:Union[str, int] = '10'):\n        \"\"\"Compute the xy values. \n\n        Parameters\n        ----------\n        illuminant : (str, optional)  \n            Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n        observer : (str|int, optional)\n            Reference *observer* in degree ('10' or '2'). by default '10'.\n\n        Returns\n        -------\n        pandas dataframe\n            It returns the xy values inside a dataframe where each column corresponds to a single file.\n        \"\"\"\n\n\n        observer = str(observer)\n\n        illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n        observers = {\n            '10': 'cie_10_1964',\n            '2' : 'cie_2_1931',\n        }\n        cmfs_observers = {\n            '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n            '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n            }\n\n        meas_ids = self.meas_ids                \n        df_sp = self.get_data(data='sp')       \n        df_xy = []\n\n\n        for df, meas_id in zip(df_sp, meas_ids):\n\n            xy_values = pd.DataFrame(index=['x','y']).T           \n\n            for col in df.columns:\n\n                sp = df[col]\n                wl = df.index\n                sd = colour.SpectralDistribution(sp,wl)                \n\n                XYZ = np.round(colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]),3)\n                xy = np.round(colour.XYZ_to_xy(XYZ),4)\n                xy_values = pd.concat([xy_values, pd.DataFrame(xy, index=['x','y']).T], axis=0)\n                xy_values.index = np.arange(0,xy_values.shape[0])\n\n            xy_values.columns = pd.MultiIndex.from_product([[meas_id], xy_values.columns])\n            df_xy.append(xy_values)\n\n        return pd.concat(df_xy, axis=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        observer = str(observer)\n\n        illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n        observers = {\n            '10': 'cie_10_1964',\n            '2' : 'cie_2_1931',\n        }\n        cmfs_observers = {\n            '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n            '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n            }\n\n        df_xy = pd.DataFrame(index=pd.Series(['x','y']))\n        df_sp = self.get_data(data='sp')\n        wl = df_sp.index\n\n        for col in df_sp.columns:\n            sp = df_sp[col]\n            sd = colour.SpectralDistribution(sp,wl)\n\n            XYZ = colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]) \n            xy = np.round(colour.XYZ_to_xy(XYZ),4)\n\n            df_xy[col] = xy\n\n        return df_xy\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.meas_ids","title":"<code>meas_ids</code>  <code>property</code>","text":"<p>Return the measurement id numbers corresponding to the input files.</p>"},{"location":"references/#microfading.microfading.MFT.wavelength","title":"<code>wavelength</code>  <code>property</code>","text":"<p>Return the wavelength range of the microfading measurements.</p>"},{"location":"references/#microfading.microfading.MFT.Lab","title":"<code>Lab(illuminant='D65', observer='10')</code>","text":"<p>Retrieve the CIE Lab* values.</p>"},{"location":"references/#microfading.microfading.MFT.Lab--parameters","title":"Parameters","text":"<p>illuminant : (str, optional)     Reference illuminant ('D65', or 'D50'). by default 'D65'.</p> (str|int, optional) <p>Reference observer in degree ('10' or '2'). by default '10'.</p>"},{"location":"references/#microfading.microfading.MFT.Lab--returns","title":"Returns","text":"<p>pandas dataframe     It returns the Lab* values inside a dataframe where each column corresponds to a single file.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def Lab(self, illuminant:Optional[str] = 'D65', observer:Optional[str] = '10'):\n    \"\"\"\n    Retrieve the CIE L*a*b* values.\n\n    Parameters\n    ----------\n    illuminant : (str, optional)  \n        Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n    observer : (str|int, optional)\n        Reference *observer* in degree ('10' or '2'). by default '10'.\n\n\n    Returns\n    -------\n    pandas dataframe\n        It returns the L*a*b* values inside a dataframe where each column corresponds to a single file.\n    \"\"\"        \n    observer = str(observer)\n\n    illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n    observers = {\n        '10': 'cie_10_1964',\n        '2' : 'cie_2_1931',\n    }\n    cmfs_observers = {\n        '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n        '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n        }\n\n    ccs_ill = colour.CCS_ILLUMINANTS[observers[observer]][illuminant]\n\n    meas_ids = self.meas_ids\n\n    if self.stdev:\n        df_sp = [x['mean'] for x in self.get_data(data='sp')]\n    else:\n        df_sp = self.get_data(data='sp')\n\n    df_Lab = []\n\n\n    for df, meas_id in zip(df_sp, meas_ids):            \n        Lab_values = pd.DataFrame(index=['L*','a*','b*']).T           \n\n        for col in df.columns:\n\n            sp = df[col]\n            wl = df.index\n            sd = colour.SpectralDistribution(sp,wl)                \n\n            XYZ = colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant])        \n            Lab = np.round(colour.XYZ_to_Lab(XYZ/100,ccs_ill),2)               \n            Lab_values = pd.concat([Lab_values, pd.DataFrame(Lab, index=['L*','a*','b*']).T], axis=0)\n            Lab_values.index = np.arange(0,Lab_values.shape[0])\n\n        Lab_values.columns = pd.MultiIndex.from_product([[meas_id], Lab_values.columns])\n        df_Lab.append(Lab_values)\n\n    return pd.concat(df_Lab, axis=1)\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.XYZ","title":"<code>XYZ(illuminant='D65', observer='10')</code>","text":"<p>Compute the XYZ values. </p>"},{"location":"references/#microfading.microfading.MFT.XYZ--parameters","title":"Parameters","text":"<p>illuminant : (str, optional)     Reference illuminant ('D65', or 'D50'). by default 'D65'.</p> (str|int, optional) <p>Reference observer in degree ('10' or '2'). by default '10'.</p>"},{"location":"references/#microfading.microfading.MFT.XYZ--returns","title":"Returns","text":"<p>pandas dataframe     It returns the XYZ values inside a dataframe where each column corresponds to a single file.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def XYZ(self, illuminant:Optional[str] = 'D65', observer:Union[str,int] = '10'):\n    \"\"\"Compute the XYZ values. \n\n    Parameters\n    ----------\n    illuminant : (str, optional)  \n        Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n    observer : (str|int, optional)\n        Reference *observer* in degree ('10' or '2'). by default '10'.\n\n    Returns\n    -------\n    pandas dataframe\n        It returns the XYZ values inside a dataframe where each column corresponds to a single file.\n    \"\"\"\n\n    observer = str(observer)\n\n    illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n\n    cmfs_observers = {\n        '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n        '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n        }\n\n    meas_ids = self.meas_ids                \n    df_sp = self.get_data(data='sp')       \n    df_XYZ = []\n\n\n    for df, meas_id in zip(df_sp, meas_ids):\n\n        XYZ_values = pd.DataFrame(index=['X','Y','Z']).T           \n\n        for col in df.columns:\n\n            sp = df[col]\n            wl = df.index\n            sd = colour.SpectralDistribution(sp,wl)                \n\n            XYZ = np.round(colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]),3)\n            XYZ_values = pd.concat([XYZ_values, pd.DataFrame(XYZ, index=['X','Y','Z']).T], axis=0)\n            XYZ_values.index = np.arange(0,XYZ_values.shape[0])\n\n        XYZ_values.columns = pd.MultiIndex.from_product([[meas_id], XYZ_values.columns])\n        df_XYZ.append(XYZ_values)\n\n    return pd.concat(df_XYZ, axis=1)\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.__init__","title":"<code>__init__(files, BWS=True, stdev=False)</code>","text":"<p>Instantiate a Microfading (MFT) class object in order to manipulate and visualize microfading analysis data.</p>"},{"location":"references/#microfading.microfading.MFT.__init__--parameters","title":"Parameters","text":"<p>files : list     A list of string, where each string corresponds to the absolute path of text or csv file that contains the data and metadata of a single microfading measurement. The content of the file requires a specific structure, for which an example can be found in \"datasets\" folder of the microfading package folder (Use the get_datasets function to retrieve the precise location of such example files). If the file structure is not respected, the script will not be able to properly read the file and access its content.</p> bool, optional <p>When False, it ignores the measurements performed on BWS samples if included. </p> bool, optional <p>Indicate whether the input files contains standard deviation values, by default False</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def __init__(self, files:list, BWS:Optional[bool] = True, stdev:Optional[bool] = False) -&gt; None:\n    \"\"\"Instantiate a Microfading (MFT) class object in order to manipulate and visualize microfading analysis data.\n\n    Parameters\n    ----------\n    files : list\n        A list of string, where each string corresponds to the absolute path of text or csv file that contains the data and metadata of a single microfading measurement. The content of the file requires a specific structure, for which an example can be found in \"datasets\" folder of the microfading package folder (Use the get_datasets function to retrieve the precise location of such example files). If the file structure is not respected, the script will not be able to properly read the file and access its content.\n\n    BWS : bool, optional\n        When False, it ignores the measurements performed on BWS samples if included. \n\n    stdev: bool, optional\n        Indicate whether the input files contains standard deviation values, by default False\n    \"\"\"\n    self.files = files\n    self.BWS = BWS\n    self.stdev = stdev\n\n    if self.BWS == False:\n        self.files = [x for x in self.files if 'BW' not in x.name]\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.data_points","title":"<code>data_points(coordinates=['dE00'], dose_unit='He', dose_values=1, index=False)</code>","text":"<p>Select colourimetric values for one or multiple light dose values.</p>"},{"location":"references/#microfading.microfading.MFT.data_points--parameters","title":"Parameters","text":"<p>coordinates : Optional[list], optional     Select the desired colourimetric coordinates from the following list: ['L', 'a','b', 'C', 'h', 'dL', 'da','db', 'dC', 'dh', 'dE76', 'dE00', 'dR_vis'], by default ['dE00']</p> Optional[str], optional <p>Select the unit of the light energy, by default ['He'] Any of the following units can be added to the list: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)</p> Union[int, float, list, tuple], optional <p>Select the values of the light energy, by default 1 A single value, a list of multiple values, or range values with a tuple (start, end, step) can be entered.</p> Optional[bool], optional <p>Whether to set the index of the returned dataframes, by default False</p>"},{"location":"references/#microfading.microfading.MFT.data_points--returns","title":"Returns","text":"<p>A list of pandas dataframes     It returns the values of the wanted colour coordinates inside dataframes where each coordinate corresponds to a column.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def data_points(self, coordinates:Optional[list] = ['dE00'], dose_unit:Optional[str] = 'He', dose_values:Union[int, float, list, tuple] = 1, index:Optional[bool] = False):\n    \"\"\"Select colourimetric values for one or multiple light dose values.\n\n    Parameters\n    ----------\n    coordinates : Optional[list], optional\n        Select the desired colourimetric coordinates from the following list: ['L*', 'a*','b*', 'C*', 'h', 'dL*', 'da*','db*', 'dC*', 'dh', 'dE76', 'dE00', 'dR_vis'], by default ['dE00']\n\n    dose_unit : Optional[str], optional\n        Select the unit of the light energy, by default ['He']\n        Any of the following units can be added to the list: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)\n\n    dose_values : Union[int, float, list, tuple], optional\n        Select the values of the light energy, by default 1\n        A single value, a list of multiple values, or range values with a tuple (start, end, step) can be entered.\n\n    index : Optional[bool], optional\n        Whether to set the index of the returned dataframes, by default False\n\n    Returns\n    -------\n    A list of pandas dataframes\n        It returns the values of the wanted colour coordinates inside dataframes where each coordinate corresponds to a column.\n    \"\"\"\n\n    # Retrieve the range light dose values\n    doses = {'He':'He_MJ/m2', 'Hv':'Hv_Mlxh', 't': 't_sec'}\n\n    if isinstance(dose_values, (float, int)):\n        dose_values = [dose_values]\n\n    elif isinstance(dose_values, tuple):\n        dose_values = np.arange(dose_values[0], dose_values[1], dose_values[2])\n\n    elif isinstance(dose_values, list):\n        dose_values = dose_values        \n\n    # Retrieve the data\n    original_data = self.get_data(data='cl')\n\n    # Added the delta LabCh values to the data dataframes   \n    if original_data[0].columns.nlevels &gt; 1:\n\n        delta_coord = [unumpy.uarray(d[coord, 'mean'], d[coord, 'std']) - unumpy.uarray(d[coord, 'mean'], d[coord, 'std'])[0] for coord in ['L*', 'a*', 'b*', 'C*', 'h'] for d in original_data]\n\n        delta_means = [unumpy.nominal_values(x) for x in delta_coord]\n        delta_stds = [unumpy.std_devs(x) for x in delta_coord]\n\n        delta_coord_mean = [(f'd{coord}', 'mean') for coord in ['L*', 'a*', 'b*', 'C*', 'h']]\n        delta_coord_std = [(f'd{coord}', 'std') for coord in ['L*', 'a*', 'b*', 'C*', 'h']]\n\n        # Add the new columns to the dictionary\n        data = []\n\n        for d in original_data:\n            print(d)\n            for coord_mean,delta_mean,coord_std,delta_std in zip(delta_coord_mean,delta_means, delta_coord_std,delta_stds):\n                print(coord_mean)\n                print(len(delta_mean))\n                d[coord_mean] = delta_mean\n                d[coord_std] = delta_std\n\n            data.append(d)\n\n\n        # Select the wanted dose_unit and coordinate        \n        wanted_data = [x[[doses[dose_unit]] + coordinates] for x in data]        \n        wanted_data = [x.set_index(x.columns[0]) for x in wanted_data]\n\n    else:\n\n        data = [d.assign(**{f'd{coord}': d[coord] - d[coord].values[0] for coord in ['L*', 'a*', 'b*', 'C*', 'h']}) for d in original_data]\n\n        # Select the wanted dose_unit and coordinate        \n        wanted_data = [x[[doses[dose_unit]] + coordinates] for x in data]        \n        wanted_data = [x.set_index(x.columns[0]) for x in wanted_data]\n\n    # Interpolation function, assuming linear interpolation\n    interp_functions = lambda x, y: interp1d(x, y, kind='linear', bounds_error=False)\n\n    # Double comprehension list to interpolate each dataframe in wanted_data\n    interpolated_data = [\n        pd.DataFrame({\n            col: interp_functions(df.index, df[col])(dose_values)\n            for col in df.columns\n        }, index=dose_values)\n        .rename_axis(doses[dose_unit])\n        .reset_index()\n        for df in wanted_data\n    ]\n\n    # Whether to set the index\n    if index:\n        interpolated_data = [x.set_index(x.columns[0]) for x in interpolated_data]\n\n    return interpolated_data       \n</code></pre>"},{"location":"references/#microfading.microfading.MFT.delta","title":"<code>delta(coordinates=['dE00'], dose_unit=['He'], rate=False)</code>","text":"<p>Retrieve the CIE delta values for a given set of colorimetric coordinates corresponding to the given microfading analyses.</p>"},{"location":"references/#microfading.microfading.MFT.delta--parameters","title":"Parameters","text":"<p>coordinates : list, optional     List of colorimetric coordinates, by default ['dE00']     Any of the following coordinates can be added to the list: 'dE76', 'dE00', 'dR_vis' , 'L', 'a', 'b', 'C', 'h'.</p> list, optional <p>List of light energy doses, by default ['He'] Any of the following units can be added to the list: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)</p> bool, optional <p>Whether to return the first derivative values of the desired coordinates, by default False</p>"},{"location":"references/#microfading.microfading.MFT.delta--returns","title":"Returns","text":"<p>type     Returns a Pandas dataframe where each column corresponds to a desired coordinate or light energy dose.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def delta(self, coordinates:Optional[list] = ['dE00'], dose_unit:Optional[list] = ['He'], rate:Optional[bool] = False):\n    \"\"\"Retrieve the CIE delta values for a given set of colorimetric coordinates corresponding to the given microfading analyses.\n\n    Parameters\n    ----------\n    coordinates : list, optional\n        List of colorimetric coordinates, by default ['dE00']\n        Any of the following coordinates can be added to the list: 'dE76', 'dE00', 'dR_vis' , 'L*', 'a*', 'b*', 'C*', 'h'.\n\n    dose_unit : list, optional\n        List of light energy doses, by default ['He']\n        Any of the following units can be added to the list: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)\n\n    rate : bool, optional\n        Whether to return the first derivative values of the desired coordinates, by default False\n\n    Returns\n    -------\n    _type_\n        Returns a Pandas dataframe where each column corresponds to a desired coordinate or light energy dose.\n    \"\"\"\n\n    doses_dic = {'He': 'He_MJ/m2', 'Hv': 'Hv_Mlxh', 't': 't_sec'} \n    doses_labels = [doses_dic[x] for x in dose_unit]\n\n    wanted_data = []\n\n\n    if self.stdev == False: \n\n        doses = self.get_data(data=doses_labels) \n        data = self.get_data(data=coordinates)        \n\n\n        for el_data,el_dose in zip(data,doses):\n            for col in el_data.columns:\n                if col in ['L*','a*','b*','C*','h']:\n                    values = el_data[col]\n                    values_delta = values - values[0]   \n\n                    el_data[col] = values_delta\n                    el_data.rename(columns={col:f'd{col}'}, inplace=True)\n\n            if rate:   \n\n                step_dose = el_dose.iloc[:,0].values[2]-el_dose.iloc[:,0].values[1]\n\n                el_data = pd.DataFrame(np.gradient(el_data.T.values, step_dose, axis=1).T, columns=el_data.columns)\n\n            wanted_data.append(pd.concat([el_dose, el_data], axis=1))\n\n\n    else:\n\n        data = self.get_data(data=coordinates)[0] - self.get_data(data=coordinates)[0].iloc[0,:]\n        doses = self.get_data(data=doses_labels)\n        wanted_data = [pd.concat([doses[0],data], axis=1)]\n\n        new_columns = []\n        for i in wanted_data:\n            for col in i.columns:\n                if col[1] in ['L*','a*','b*','C*','h']:\n                    new_columns.append((col[0], f'd{col[1]}'))\n                else:\n                    new_columns.append(col)\n\n            i.columns = pd.MultiIndex.from_tuples(new_columns, names=i.columns.names)          \n\n\n    return wanted_data\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.fit_data","title":"<code>fit_data(plot=False, return_data=False, dose_unit='He', coordinate='dE00', equation='c0*(x**c1)', initial_params=[0.1, 0.0], x_range=(0, 1001, 1), save=False, path_fig='default')</code>","text":"<p>Fit the values of a given colourimetric coordinates. </p>"},{"location":"references/#microfading.microfading.MFT.fit_data--parameters","title":"Parameters","text":"<p>plot : bool, optional     Whether to show the fitted data, by default False</p> bool, optional <p>Whether to return the fitted data, by default False</p> string, optional <p>Select the light energy dose, by default 'He' Any of the following units can be used: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)</p> string, optional <p>Select the desired colourimetric coordinates from the following list: ['L', 'a','b', 'C', 'h', 'dL', 'da','db', 'dC', 'dh', 'dE76', 'dE00', 'dR_vis'], by default 'dE00'</p> str, optional <p>Mathematical equation used to fit the coordinate values, by default 'c0(x*c1)'</p> Optional[List[float]], optional <p>Initial guesses of the 'c' parameters given in the equation (c0, c1, c2, etc.), by default [0.1, 0.0]</p> Optional[Tuple[int]], optional <p>Values along which the fitted values should be computed (start, end, step), by default (0, 1001, 1)</p> Optional[bool], optional <p>Whether to save the plot, by default False</p> Optional[str], optional <p>Absolute path of the figure to be saved, by default 'default'</p>"},{"location":"references/#microfading.microfading.MFT.fit_data--returns","title":"Returns","text":"<p>Union[None, Tuple[np.ndarray, np.ndarray]]     description</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def fit_data(self, plot:Optional[bool] = False, return_data:Optional[bool] = False, dose_unit:Optional[str] = 'He', coordinate:Optional[str] = 'dE00', equation:Optional[str] = 'c0*(x**c1)', initial_params:Optional[List[float]] = [0.1, 0.0], x_range:Optional[Tuple[int]] = (0, 1001, 1), save: Optional[bool] = False, path_fig: Optional[str] = 'default') -&gt; Union[None, Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"Fit the values of a given colourimetric coordinates. \n\n    Parameters\n    ----------\n    plot : bool, optional\n        Whether to show the fitted data, by default False\n\n    return_data : bool, optional\n        Whether to return the fitted data, by default False\n\n    dose_unit : string, optional\n        Select the light energy dose, by default 'He'\n        Any of the following units can be used: 'He', 'Hv', 't'. Where 'He' corresponds to radiant energy (MJ/m2), 'Hv' to exposure dose (Mlxh), and 't' to times (sec)\n\n    coordinates : string, optional\n        Select the desired colourimetric coordinates from the following list: ['L*', 'a*','b*', 'C*', 'h', 'dL*', 'da*','db*', 'dC*', 'dh', 'dE76', 'dE00', 'dR_vis'], by default 'dE00'\n\n    equation : str, optional\n        Mathematical equation used to fit the coordinate values, by default 'c0*(x**c1)'\n\n    initial_params : Optional[List[float]], optional\n        Initial guesses of the 'c' parameters given in the equation (c0, c1, c2, etc.), by default [0.1, 0.0]\n\n    x_range : Optional[Tuple[int]], optional\n        Values along which the fitted values should be computed (start, end, step), by default (0, 1001, 1)\n\n    save : Optional[bool], optional\n        Whether to save the plot, by default False\n\n    path_fig : Optional[str], optional\n        Absolute path of the figure to be saved, by default 'default'\n\n    Returns\n    -------\n    Union[None, Tuple[np.ndarray, np.ndarray]]\n        _description_\n    \"\"\"\n\n    # Retrieve the range light dose values\n    doses = {'He':'He_MJ/m2', 'Hv':'Hv_Mlxh', 't': 't_sec'}  \n    x_values = np.arange(*x_range)\n\n    # Retrieve the data\n    original_data = self.get_data(data='cl')\n\n    #original_data = self.get_data(data='dE') if self.data_category == 'interim' else self.get_data(data='dE')[0].astype(float)\n\n    # Added the delta LabCh values to the data dataframes\n    coordinates = ['L*', 'a*', 'b*', 'C*', 'h']\n    data = [d.assign(**{f'd{coord}': d[coord] - d[coord].values[0] for coord in coordinates}) for d in original_data]\n\n    # Select the wanted dose_unit and coordinate\n    wanted_data = [x[[doses[dose_unit], coordinate]] for x in data]\n    wanted_data = [x.set_index(x.columns[0]) for x in wanted_data]\n\n    # Define the function to fit\n    def fit_function(x, *params):\n        param_dict = {f'c{i}': param for i, param in enumerate(params)}\n        param_dict['x'] = x\n        return eval(equation, globals(), param_dict)\n\n    # Define boundaries for the parameters\n    #bounds = ([-np.inf] * len(initial_params), [np.inf, 1]) if len(initial_params) == 2 else ([-np.inf] * len(initial_params), [np.inf, 1, np.inf])\n\n    # Create an empty dataframe for the fitted data\n    fitted_data = pd.DataFrame(index=pd.Series(x_values))\n\n    # Empty list to store the labels\n    fitted_labels = []\n\n    # Emtpy list to store the optimized parameters\n    fitted_parameters = []\n\n    for d in wanted_data:\n        # retrieve the x(light dose) and y(coordinate) values\n        x, y = d.index, d.iloc[:,0]\n\n        # perform the curve fitting\n        optimized_params, _ = curve_fit(fit_function, x, y, p0=initial_params, ) # bounds=bounds\n\n        # generate fitted y data\n        fitted_y = fit_function(x_values, *optimized_params)\n\n        # append it to the fitted_data dataframe\n        fitted_data = pd.concat([fitted_data, pd.DataFrame(fitted_y, index=pd.Series(x_values))], axis=1)\n\n        # Calculate R-squared value\n        residuals = y - fit_function(x, *optimized_params)\n        ss_res, ss_tot = np.sum(residuals**2), np.sum((y - np.mean(y))**2)        \n        r_squared = np.round(1 - (ss_res / ss_tot), 3)\n\n        # Create a string representation of the equation with optimized parameters\n        optimized_equation = equation\n        for i, param in enumerate(optimized_params):\n            optimized_equation = optimized_equation.replace(f'c{i}', str(np.round(param,2)))\n\n        fitted_labels.append(f'{optimized_equation}, $R^2$ = {r_squared}')\n        fitted_parameters.append(optimized_params)\n\n    fitted_data.columns = [f'{x.split(\".\")[-1]}, $y$ = {y}' for x,y in zip(self.meas_ids, fitted_labels)]         \n\n    if plot:\n        labels_eq = {\n            'L*': r'CIE $L^*$',\n            'a*': r'CIE $a^*$',\n            'b*': r'CIE $b^*$',\n            'C*': r'CIE $C^*$',\n            'h': r'CIE $h$',\n            'dE76': r'$\\Delta E^*_{ab}$',\n            'dE00': r'$\\Delta E^*_{00}$',\n            'dR_VIS': r'$\\Delta R_{\\rm vis}$',\n            'dL*': r'CIE $\\Delta L^*$',\n            'da*': r'CIE $\\Delta a^*$',\n            'db*': r'CIE $\\Delta b^*$',\n            'dC*': r'CIE $\\Delta C^*$',\n            'dh': r'CIE $\\Delta h$',\n        }\n\n        labels_H = {\n            'Hv': 'Exposure dose $H_v$ (Mlxh)',\n            'He': 'Radiant Exposure $H_e$ (MJ/m\u00b2)',\n            't' : 'Exposure duration (seconds)'\n        }\n\n        sns.set_theme(context='paper', font='serif', palette='colorblind')\n        fig, ax = plt.subplots(1,1, figsize=(10,6))\n        fs = 24\n\n\n        pd.concat(wanted_data, axis=1).plot(ax=ax, color='0.7', ls='-', lw=5, legend=False)\n        fitted_data.plot(ax=ax, lw=2, ls='--')\n\n        #meas_line, = ax.plot(x,y, ls='-', lw=3)            \n        #fitted_line, = ax.plot(x_values,fitted_y, ls='--', lw=2)\n\n        ax.set_xlabel(labels_H[dose_unit], fontsize=fs)\n        ax.set_ylabel(labels_eq[coordinate],fontsize=fs)\n\n        #title = f'Microfading, {self.Id}, data fitting'\n        #ax.set_title(title, fontsize = fs-4)   \n\n        '''\n        if coordinate.startswith('d'):                \n            ax.set_ylim(0) \n        '''\n\n        ax.set_xlim(0)    \n\n        ax.xaxis.set_tick_params(labelsize=fs)\n        ax.yaxis.set_tick_params(labelsize=fs)\n\n        #plt.legend([meas_line,fitted_line], [\"original data\",f\"$f(x) = {optimized_equation}$\\n$R^2 = {r_squared:.3f}$\"],fontsize=fs-6)\n        #plt.tight_layout()\n\n\n        if save:\n\n            filename = self.make_filename('dEfit')\n\n            if save:            \n                if path_fig == 'default':\n                    path_fig = self.get_folder_figures() / filename\n\n                if path_fig == 'cwd':\n                    path_fig = f'{os.getcwd()}/{filename}' \n\n                plt.savefig(path_fig, dpi=300, facecolor='white')\n\n        plt.show()\n\n    if return_data:\n        return fitted_parameters, fitted_data\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.get_data","title":"<code>get_data(data='all', xarray=False)</code>","text":"<p>Retrieve the microfading data.</p>"},{"location":"references/#microfading.microfading.MFT.get_data--parameters","title":"Parameters","text":"<p>data : str|list, optional     Possibility to select the type of data, by default 'all'.     When 'all', it returns all the data (spectral and colorimetric).     When 'sp', it only returns the spectral data.     When 'cl', it only returns the colorimetric data.     When 'Lab', it returns the CIE Lab values.     A list of strings can be entered to select specific colourimetric data among the following: ['dE76,'dE00','dR_vis', 'L', 'a', 'b', 'C*', 'h'].</p> bool, optional <p>When True, the data are returned as an xarray.Dataset object, else as pandas dataframe object, by default False.</p>"},{"location":"references/#microfading.microfading.MFT.get_data--returns","title":"Returns","text":"<p>returns a list of pandas dataframes or xarray.Dataset objects</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def get_data(self, data:Union[str, list] = 'all', xarray:Optional[bool] = False):\n    \"\"\"Retrieve the microfading data.\n\n    Parameters\n    ----------\n    data : str|list, optional\n        Possibility to select the type of data, by default 'all'.\n        When 'all', it returns all the data (spectral and colorimetric).\n        When 'sp', it only returns the spectral data.\n        When 'cl', it only returns the colorimetric data.  \n        When 'Lab', it returns the CIE L*a*b* values.\n        A list of strings can be entered to select specific colourimetric data among the following: ['dE76,'dE00','dR_vis', 'L*', 'a*', 'b*', 'C*', 'h'].\n\n    xarray : bool, optional\n        When True, the data are returned as an xarray.Dataset object, else as pandas dataframe object, by default False.\n\n    Returns\n    -------\n    returns a list of pandas dataframes or xarray.Dataset objects\n    \"\"\"\n\n    all_files = self.read_files(sheets=['spectra','CIELAB'])\n    all_data = []\n    data_sp = [] \n    data_cl = [] \n\n    for data_file in all_files:\n\n        sp = data_file[0].iloc[:,1:].values            \n        wl = data_file[0].iloc[:,0].values\n        He = data_file[1]['He_MJ/m2'].values\n        Hv = data_file[1]['Hv_Mlxh'].values\n        t = data_file[1]['t_sec'].values\n        L = data_file[1][\"L*\"].values\n        a = data_file[1][\"a*\"].values\n        b = data_file[1][\"b*\"].values\n        C = data_file[1][\"C*\"].values\n        h = data_file[1][\"h\"].values\n        dE76 = data_file[1][\"dE76\"].values\n        dE00 = data_file[1][\"dE00\"].values\n        dR_vis = data_file[1][\"dR_vis\"].values\n\n        spectral_data = xr.Dataset(\n            {\n                'sp': (['wavelength','dose'], sp)                \n            },\n            coords={\n                'wavelength': wl,   \n                'dose': He,\n                'He': ('dose', He),\n                'Hv': ('dose', Hv),  # Match radiant energy\n                't': ('dose', t)  # Match radiant energy\n            }\n        )\n\n        color_data = xr.Dataset(\n            {\n                'L*': (['dose'], L),\n                'a*': (['dose'], a),\n                'b*': (['dose'], b),\n                'C*': (['dose'], C),\n                'h': (['dose'], h),\n                'dE76': (['dose'], dE76),\n                'dE00': (['dose'], dE00),\n                'dR_vis': (['dose'], dR_vis),\n            },\n            coords={                    \n                'He': ('dose',He),\n                'Hv': ('dose',Hv),\n                't': ('dose',t),\n            }\n        )                \n\n        sp = spectral_data.set_xindex([\"He\",\"Hv\",\"t\"])\n        cl = color_data.set_xindex([\"He\",\"Hv\",\"t\"])\n        combined_data = xr.merge([sp, cl])\n\n    all_data.append(combined_data)            \n\n\n    if data == 'all':\n        if xarray == False:\n            [data_sp.append(x[0]) for x in all_files]\n            [data_cl.append(x[1]) for x in all_files]\n            return data_sp, data_cl\n\n        else:\n            return all_data\n\n    elif data == 'sp':\n        if xarray == False:\n            [data_sp.append(x[0]) for x in all_files]                            \n        else:\n            data_sp = [x.sp for x in all_data]\n\n        return data_sp\n\n    elif data == 'cl':\n        if xarray == False:\n            [data_cl.append(x[1]) for x in all_files]\n        else:\n            data_cl = [x[['L*','a*','b*','C*','h','dE76','dE00','dR_vis']] for x in all_data]\n\n        return data_cl\n\n    elif data == 'Lab':\n        if xarray == False:\n            [data_cl.append(x[1][['L*','a*','b*']]) for x in all_files]\n        else:\n            data_cl = [x[['L*','a*','b*']] for x in all_data]\n\n        return data_cl\n\n    elif isinstance(data,list):\n        if xarray == False:\n            dic_doses = {'He': 'He_MJ/m2', 'Hv':'Hv_Mlxh', 't':'t_sec'}\n            data = [dic_doses[x] if x in dic_doses.keys() else x for x in data]\n            [data_cl.append(x[1][data]) for x in all_files]\n\n        else:\n            data = [elem for elem in data if elem not in ['Hv','He','t']]\n            data_cl = [x[data] for x in all_data]\n\n        return data_cl\n\n    else:\n        print(\"Enter a valid data parameter. It can either be a string ('sp', 'cl', 'Lab', 'all') or a list of strings ['dE00','dE76', 'L*', 'a*', 'b*', 'C*', 'h']\")\n        return None\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.get_metadata","title":"<code>get_metadata(labels='all')</code>","text":"<p>Retrieve the metadata.</p>"},{"location":"references/#microfading.microfading.MFT.get_metadata--parameters","title":"Parameters","text":"<p>labels : Optional[list], optional     A list of strings corresponding to the wanted metadata labels, by default 'all'     The metadata labels can be found in the 'info' sheet of microfading excel files.     When 'all', it returns all the metadata</p>"},{"location":"references/#microfading.microfading.MFT.get_metadata--returns","title":"Returns","text":"<p>pandas dataframe     It returns the metadata inside a pandas dataframe where each column corresponds to a single file.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def get_metadata(self, labels:Optional[list] = 'all'):\n    \"\"\"Retrieve the metadata.\n\n    Parameters\n    ----------\n    labels : Optional[list], optional\n        A list of strings corresponding to the wanted metadata labels, by default 'all'\n        The metadata labels can be found in the 'info' sheet of microfading excel files.\n        When 'all', it returns all the metadata\n\n    Returns\n    -------\n    pandas dataframe\n        It returns the metadata inside a pandas dataframe where each column corresponds to a single file.\n    \"\"\"\n\n    df = self.read_files()\n    metadata = [x[0] for x in df]\n\n    df_metadata = pd.DataFrame(index = metadata[0].set_index('parameter').index)\n\n    for m in metadata:\n        m = m.set_index('parameter')\n        Id = m.loc['meas_id']['value']\n\n        df_metadata[Id] = m['value']\n\n    if labels == 'all':\n        return df_metadata\n\n    else:            \n        return df_metadata.loc[labels]\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.mean","title":"<code>mean(return_data=True, criterion='group', save=False, folder='default', filename='default')</code>","text":"<p>Compute mean and standard deviation values of several microfading measurements.</p>"},{"location":"references/#microfading.microfading.MFT.mean--parameters","title":"Parameters","text":"<p>return_data : Optional[bool], optional     Whether to return the data, by default True        </p> Optional[str], optional <p>description, by default 'group'            </p> Optional[bool], optional <p>Whether to save the average data as an excel file, by default False</p> Optional[str], optional <p>Folder where the excel file will be saved, by default 'default' When 'default', the file will be saved in the same folder as the input files When '.', the file will be saved in the current working directory One can also enter a valid path as a string.</p> Optional[str], optional <p>Filename of the excel file containing the average values, by default 'default' When 'default', it will use the filename of the first input file One can also enter a filename, but without a filename extension.</p>"},{"location":"references/#microfading.microfading.MFT.mean--returns","title":"Returns","text":"<p>tuple, excel file     It returns a tuple composed of three elements (info, CIELAB data, spectral data). When 'save' is set to True, an excel is created to stored the tuple inside three distinct excel sheet (info, CIELAB, spectra).</p>"},{"location":"references/#microfading.microfading.MFT.mean--raises","title":"Raises","text":"<p>RuntimeError     description</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def mean(self, return_data:Optional[bool] = True, criterion:Optional[str] = 'group', save:Optional[bool] = False, folder:Optional[str] = 'default', filename:Optional[str] = 'default'):\n    \"\"\"Compute mean and standard deviation values of several microfading measurements.\n\n    Parameters\n    ----------\n    return_data : Optional[bool], optional\n        Whether to return the data, by default True        \n\n    criterion : Optional[str], optional\n        _description_, by default 'group'            \n\n    save : Optional[bool], optional\n        Whether to save the average data as an excel file, by default False\n\n    folder : Optional[str], optional\n        Folder where the excel file will be saved, by default 'default'\n        When 'default', the file will be saved in the same folder as the input files\n        When '.', the file will be saved in the current working directory\n        One can also enter a valid path as a string.\n\n    filename : Optional[str], optional\n        Filename of the excel file containing the average values, by default 'default'\n        When 'default', it will use the filename of the first input file\n        One can also enter a filename, but without a filename extension.\n\n    Returns\n    -------\n    tuple, excel file\n        It returns a tuple composed of three elements (info, CIELAB data, spectral data). When 'save' is set to True, an excel is created to stored the tuple inside three distinct excel sheet (info, CIELAB, spectra).\n\n    Raises\n    ------\n    RuntimeError\n        _description_\n    \"\"\"\n\n    if len(self.files) &lt; 2:        \n        raise RuntimeError('Not enough files. At least two measurement files are required to compute the average values.')\n\n\n    def mean_std_with_nan(arrays):\n        '''Compute the mean of several numpy arrays of different shapes.'''\n\n        # Find the maximum shape\n        max_shape = np.max([arr.shape for arr in arrays], axis=0)\n\n        # Create arrays with NaN values\n        nan_arrays = [np.full(max_shape, np.nan) for _ in range(len(arrays))]\n\n        # Fill NaN arrays with actual values\n        for i, arr in enumerate(arrays):\n            nan_arrays[i][:arr.shape[0], :arr.shape[1]] = arr\n\n        # Calculate mean\n        mean_array = np.nanmean(np.stack(nan_arrays), axis=0)\n\n        # Calculate std\n        std_array = np.nanstd(np.stack(nan_arrays), axis=0)\n\n        return mean_array, std_array\n\n\n    def to_float(x):\n        try:\n            return float(x)\n        except ValueError:\n            return x\n\n\n    ###### SPECTRAL DATA #######\n\n    data_sp = self.get_data(data='sp')\n\n    # Get the energy dose step\n    H_values = [x.columns.astype(float) for x in data_sp]       \n    step_H = sorted(set([x[2] - x[1] for x in H_values]))[0]\n    highest_He = np.max([x[-1] for x in H_values])\n\n    # Average the spectral data\n    sp = mean_std_with_nan(data_sp)\n    sp_mean = sp[0]\n    sp_std = sp[1] \n\n\n    # Wanted energy dose values          \n    wanted_H = np.round(np.arange(0,highest_He+step_H,step_H),1)  \n\n    if len(wanted_H) != sp_mean.shape[1]:            \n        wanted_H = np.linspace(0,highest_He,sp_mean.shape[1])\n\n    # Retrieve the wavelength range\n    wl = self.wavelength.iloc[:,0]\n\n\n    # Create a multi-index pandas DataFrame\n    H_tuples = [(dose, measurement) for dose in wanted_H for measurement in ['mean', 'std']]\n    multiindex_cols = pd.MultiIndex.from_tuples(H_tuples, names=['He_MJ/m2', 'Measurement'])\n\n    data_df_sp = np.empty((len(wl), len(wanted_H) * 2))       \n    data_df_sp[:, 0::2] = sp_mean\n    data_df_sp[:, 1::2] = sp_std\n    df_sp_final = pd.DataFrame(data_df_sp,columns=multiindex_cols, index=wl)\n    df_sp_final.index.name = 'wavelength_nm'\n\n\n\n    ###### COLORIMETRIC DATA #######\n\n    data_cl = self.get_data(data='dE')\n    columns_cl = data_cl[0].columns\n\n    # Average the colorimetric data    \n    cl = mean_std_with_nan(data_cl)\n    cl_mean = cl[0]\n    cl_std = cl[1]\n\n    # Create a multi-index pandas DataFrame\n    cl_tuples = [(x, measurement) for x in data_cl[0].columns for measurement in ['mean', 'std']]\n    multiindex_cols = pd.MultiIndex.from_tuples(cl_tuples, names=['coordinates', 'Measurement'])\n\n    data_df_cl = np.empty((cl_mean.shape[0], cl_mean.shape[1] * 2))       \n    data_df_cl[:, 0::2] = cl_mean\n    data_df_cl[:, 1::2] = cl_std\n    df_cl_final = pd.DataFrame(data_df_cl,columns=multiindex_cols, )\n    df_cl_final.drop([('He_MJ/m2','std'), ('Hv_Mlxh','std'), ('t_sec','std')], axis=1, inplace=True)\n\n    mapper = {('He_MJ/m2', 'mean'): ('He_MJ/m2', 'value'), ('Hv_Mlxh', 'mean'): ('Hv_Mlxh', 'value'), ('t_sec', 'mean'): ('t_sec', 'value')}\n    df_cl_final.columns = pd.MultiIndex.from_tuples([mapper.get(x, x) for x in df_cl_final.columns])\n\n\n    cl_cols = df_cl_final.columns\n    cl_cols_level1 = [x[0] for x in cl_cols]\n    cl_cols_level2 = [x[1] for x in cl_cols]\n    df_cl_final.columns = np.arange(0,df_cl_final.shape[1])\n\n    df_cl_final = pd.concat([pd.DataFrame(data=np.array([cl_cols_level2])), df_cl_final])\n    df_cl_final.columns = cl_cols_level1\n    df_cl_final = df_cl_final.set_index(df_cl_final.columns[0])\n\n\n    ###### INFO #######\n\n    data_info = self.get_metadata().fillna(' ')\n\n    # Select the first column as a template\n    df_info = data_info.iloc[:,0]\n\n\n    # Rename title file\n    df_info.rename({'[SINGLE MICRO-FADING ANALYSIS]': '[MEAN MICRO-FADING ANALYSES]'}, inplace=True)\n\n    # Date time\n    most_recent_dt = max(data_info.loc['date_time'])\n    df_info.loc['date_time'] = most_recent_dt\n\n    # Project data info\n    df_info.loc['project_id'] = '_'.join(sorted(set(data_info.loc['project_id'].values)))\n    df_info.loc['projectleider'] = '_'.join(sorted(set(data_info.loc['projectleider'].values)))\n    df_info.loc['meelezer'] = '_'.join(sorted(set(data_info.loc['meelezer'].values)))\n    df_info.loc['aanvraagdatum'] = '_'.join(sorted(set(data_info.loc['aanvraagdatum'].values)))\n    df_info.loc['uiterste_datum'] = '_'.join(sorted(set(data_info.loc['uiterste_datum'].values)))\n\n    # Object data info\n    if len(set([x.split('_')[0] for x in data_info.loc['institution'].values])) &gt; 1:\n        df_info.loc['institution'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['institution'].values])))\n\n    df_info.loc['object_id'] = '_'.join(sorted(set(data_info.loc['object_id'].values)))\n    df_info.loc['object_category'] = '_'.join(sorted(set(data_info.loc['object_category'].values)))\n    df_info.loc['object_type'] = '_'.join(sorted(set(data_info.loc['object_type'].values)))\n    df_info.loc['object_technique'] = '_'.join(sorted(set(data_info.loc['object_technique'].values)))\n    df_info.loc['object_title'] = '_'.join(sorted(set(data_info.loc['object_title'].values)))\n    df_info.loc['object_name'] = '_'.join(sorted(set(data_info.loc['object_name'].values)))\n    df_info.loc['object_creator'] = '_'.join(sorted(set(data_info.loc['object_creator'].values)))\n    df_info.loc['object_date'] = '_'.join(sorted(set(data_info.loc['object_date'].values)))\n    df_info.loc['object_support'] = '_'.join(sorted(set(data_info.loc['object_support'].values)))\n    df_info.loc['color'] = '_'.join(sorted(set(data_info.loc['color'].values)))\n    df_info.loc['colorants'] = '_'.join(sorted(set(data_info.loc['colorants'].values)))\n    df_info.loc['colorants_name'] = '_'.join(sorted(set(data_info.loc['colorants_name'].values)))\n    df_info.loc['binding'] = '_'.join(sorted(set(data_info.loc['binding'].values)))\n    df_info.loc['ratio'] = '_'.join(sorted(set(data_info.loc['ratio'].values)))\n    df_info.loc['thickness_microns'] = '_'.join(sorted(set(data_info.loc['thickness_microns'].values)))\n    df_info.loc['status'] = '_'.join(sorted(set(data_info.loc['status'].values)))\n\n    # Device data info\n    if len(set(data_info.loc['device'].values)) &gt; 1:\n        df_info.loc['device'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['device'].values])))\n\n    df_info.loc['measurement_mode'] = '_'.join(sorted(set(data_info.loc['measurement_mode'].values)))\n    df_info.loc['zoom'] = '_'.join(sorted(set(data_info.loc['zoom'].values)))\n    df_info.loc['iris'] = '_'.join(sorted(set(str(data_info.loc['iris'].values))))\n    df_info.loc['geometry'] = '_'.join(sorted(set(data_info.loc['geometry'].values)))\n    df_info.loc['distance_ill_mm'] = '_'.join(sorted(set(str(data_info.loc['distance_ill_mm'].values))))\n    df_info.loc['distance_coll_mm'] = '_'.join(sorted(set(str(data_info.loc['distance_coll_mm'].values))))       \n\n    if len(set(data_info.loc['fiber_fading'].values)) &gt; 1:\n        df_info.loc['fiber_fading'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['fiber_fading'].values])))\n\n    if len(set(data_info.loc['fiber_ill'].values)) &gt; 1:\n        df_info.loc['fiber_ill'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['fiber_ill'].values])))\n\n    if len(set(data_info.loc['fiber_coll'].values)) &gt; 1:\n        df_info.loc['fiber_coll'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['fiber_coll'].values])))\n\n    if len(set(data_info.loc['lamp_fading'].values)) &gt; 1:\n        df_info.loc['lamp_fading'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['lamp_fading'].values])))\n\n    if len(set(data_info.loc['lamp_ill'].values)) &gt; 1:\n        df_info.loc['lamp_ill'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['lamp_ill'].values])))\n\n    if len(set(data_info.loc['filter_fading'].values)) &gt; 1:\n        df_info.loc['filter_fading'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['filter_fading'].values])))\n\n    if len(set(data_info.loc['filter_ill'].values)) &gt; 1:\n        df_info.loc['filter_ill'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['filter_ill'].values])))\n\n    if len(set(data_info.loc['white_ref'].values)) &gt; 1:\n        df_info.loc['white_ref'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['white_ref'].values])))\n\n\n    # Analysis data info\n\n    criterion_value = df_info.loc[criterion]\n    object_id = df_info.loc['object_id']\n    if criterion == 'group':            \n        df_info.loc['meas_id'] = f'MF.{object_id}.{criterion_value}'\n    elif criterion == 'object' or criterion == 'project':\n         df_info.loc['meas_id'] = f'MF.{criterion_value}'\n    else:\n        print('Choose one of the following options for the criterion parameter: [\"group\", \"object\", \"project\"]')\n\n    meas_nbs = '-'.join([x.split('.')[-1] for x in self.meas_ids])\n    df_info.loc['group'] = f'{\"-\".join(sorted(set(data_info.loc[\"group\"].values)))}_{meas_nbs}'    \n    df_info.loc['group_description'] = '_'.join(sorted(set(data_info.loc['group_description'].values)))\n    df_info.loc['background'] = '_'.join(sorted(set(data_info.loc['background'].values)))  \n\n    if len(set(data_info.loc['specular_component'].values)) &gt; 1:\n        df_info.loc['specular_component'] = '_'.join(sorted(set([x.split('_')[0] for x in data_info.loc['specular_component'].values]))) \n\n\n    df_info.loc['integration_time_ms'] = np.round(np.mean(data_info.loc['integration_time_ms'].astype(float).values),1)\n    df_info.loc['average'] = '_'.join([str(x) for x in sorted(set(data_info.loc['average'].astype(str).values))]) \n    df_info.loc['duration_min'] = np.round(np.mean(data_info.loc['duration_min'].values),1)\n    df_info.loc['interval_sec'] = '_'.join([str(x) for x in sorted(set(data_info.loc['interval_sec'].values))])\n    df_info.loc['measurements_N'] = '_'.join([str(x) for x in sorted(set(data_info.loc['measurements_N'].astype(str).values))])\n    df_info.loc['illuminant'] = '_'.join(sorted(set(data_info.loc['illuminant'].values)))\n    df_info.loc['observer'] = '_'.join(sorted(set(data_info.loc['observer'].values)))\n\n\n    # Beam data info\n\n    df_info.loc['beam_photo'] = '_'.join(sorted(set(data_info.loc['beam_photo'].values)))\n    df_info.loc['resolution_micron/pixel'] = '_'.join(sorted(set(str(data_info.loc['resolution_micron/pixel'].values))))\n\n    fwhm = data_info.loc['FWHM_micron']\n    fwhm_avg = np.mean([i for i in [to_float(x) for x in fwhm] if isinstance(i, (int, float))])\n    df_info.loc['FWHM_micron'] = fwhm_avg\n\n    power_info = data_info.loc['power_mW']\n    power_avg = np.mean([ufloat_fromstr(x.split('_')[1]) for x in power_info])\n    power_ids = '-'.join(sorted(set([x.split('_')[0] for x in power_info])))\n    df_info.loc['power_mW'] = f'{power_ids}_{power_avg}' \n\n    irr_values = [str(ufloat(x,0)) if isinstance(x, int) else x for x in data_info.loc['irradiance_W/m**2'] ] \n    irr_mean = np.int32(np.mean([unumpy.nominal_values(ufloat_fromstr(x)) for x in irr_values]))\n    irr_std = np.int32(np.std([unumpy.nominal_values(ufloat_fromstr(x)) for x in irr_values]))\n    irr_avg = ufloat(irr_mean, irr_std)    \n    df_info.loc['irradiance_W/m**2'] = irr_avg\n\n    lm = [x for x in data_info.loc['luminuous_flux_lm'].values]\n    lm_avg = np.round(np.mean(lm),3)\n    df_info.loc['luminuous_flux_lm'] = lm_avg\n\n    ill = [x for x in data_info.loc['illuminance_Mlx']]\n    ill_avg = np.round(np.mean(ill),3)\n    df_info.loc['illuminance_Mlx'] = ill_avg\n\n\n    # Results data info\n    df_info.loc['totalDose_He_MJ/m**2'] = df_cl_final.index.values[-1]\n    df_info.loc['totalDose_Hv_Mlxh'] = df_cl_final['Hv_Mlxh'].values[-1]\n    df_info.loc['fittedEqHe_dE00'] = ''\n    df_info.loc['fittedEqHv_dE00'] = ''\n    df_info.loc['fittedRate_dE00_at_2Mlxh'] = ''\n    df_info.loc['fittedRate_dE00_at_20MJ/m**2'] = ''\n    df_info.loc['dE00_at_300klxh'] = ''\n    df_info.loc['dE00_at_3MJ/m**2'] = ''\n    df_info.loc['dEab_final'] = ufloat(df_cl_final['dE76'].values[-1][0], df_cl_final['dE76'].values[-1][1])\n    df_info.loc['dE00_final'] = ufloat(df_cl_final['dE00'].values[-1][0], df_cl_final['dE00'].values[-1][1])\n    df_info.loc['dR_VIS_final'] = ufloat(df_cl_final['dR_vis'].values[-1][0], df_cl_final['dR_vis'].values[-1][1])\n    df_info.loc['Hv_at_1dE00'] = ''\n    df_info.loc['BWSE'] = ''\n\n    # Rename the column\n    df_info.name = 'value'\n\n\n    ###### SAVE THE MEAN DATAFRAMES #######\n\n    if save:  \n\n        # set the folder\n        if folder == \".\":\n            folder = Path('.')  \n\n        elif folder == 'default':\n            folder = Path(self.files[0]).parent\n\n        else:\n            if Path(folder).exists():\n                folder = Path(folder)         \n\n        # set the filename\n        if filename == 'default':\n            filename = f'{Path(self.files[0]).stem}_MEAN{Path(self.files[0]).suffix}'\n\n        else:\n            filename = f'{filename}.xlsx'\n\n\n        # create a excel writer object\n        with pd.ExcelWriter(folder / filename) as writer:\n\n            df_info.to_excel(writer, sheet_name='info', index=True)\n            df_cl_final.to_excel(writer, sheet_name=\"CIELAB\", index=True)\n            df_sp_final.to_excel(writer, sheet_name='spectra', index=True)\n\n\n    ###### RETURN THE MEAN DATAFRAMES #######\n\n    if return_data:\n        return df_info, df_cl_final, df_sp_final\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.plot_sp","title":"<code>plot_sp(stds=[], spectra='i', labels='default', title=None, fontsize=24, fontsize_legend=26, wl_range=None, colors=None, lw=2, ls='-', save=False, path_fig='cwd', derivation=False, smooth=False, smooth_params=[10, 1], report=False)</code>","text":"<p>Plot the reflectance spectra corresponding to the associated microfading analyses.</p>"},{"location":"references/#microfading.microfading.MFT.plot_sp--parameters","title":"Parameters","text":"<p>stds : list, optional      A list of standard variation values respective to each element given in the data parameter, by default []</p> Optional[str], optional <p>Define which spectra to display, by default 'i' Use 'i' for initial spectral, 'f' for final spectra, 'i+f' for initial and final spectra, or 'all' for all the spectra.</p> Union[str, list], optional <p>description, by default 'default'</p> str, optional <p>Whether to add a title to the plot, by default None</p> int, optional <p>Fontsize of the plot (title, ticks, and labels), by default 24</p> int, optional <p>Fontsize of the legend, by default 26</p> tuple, optional <p>Define the wavelength range, by default None</p> Union[str, list], optional <p>Define the colors of the reflectance curves, by default None When 'sample', the color of each line will be based on srgb values computed from the reflectance values. Alternatively, a single string value can be used to define the color (see matplotlib colour values) or a list of matplotlib colour values can be used. </p> Union[int, list], optional <p>Define the width of the plot lines, by default 2 It can be a single integer value that will apply to all the curves. Or a list of integers can be used where the number of integer elements should match the number of reflectance curves.</p> Union[str, list], optional <p>Define the line style of the plot lines, by default '-' It can be a string ('-', '--', ':', '-.') that will apply to all the curves. Or a list of string can be used where the number of string elements should match the number of reflectance curves.</p> bool, optional <p>Whether to save the figure, by default False</p> str, optional <p>Absolute path required to save the figure, by default 'cwd' When 'cwd', it will save the figure in the current working directory.</p> bool, optional <p>Wether to compute and display the first derivative values of the spectra, by default False</p> bool, optional <p>Whether to smooth the reflectance curves, by default False</p> list, optional <p>Parameters related to the Savitzky-Golay filter, by default [10,1] Enter a list of two integers where the first value corresponds to the window_length and the second to the polyorder value. </p> Optional[bool], optional <p>description, by default False</p>"},{"location":"references/#microfading.microfading.MFT.plot_sp--returns","title":"Returns","text":"<p>type description</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def plot_sp(self, stds=[], spectra:Optional[str] = 'i', labels:Union[str,list] = 'default', title:Optional[str] = None, fontsize:Optional[int] = 24, fontsize_legend:Optional[int] = 26, wl_range:Optional[tuple] = None, colors:Union[str,list] = None, lw:Union[int, list] = 2, ls:Union[str, list] = '-', save=False, path_fig='cwd', derivation=False, smooth=False, smooth_params=[10,1], report:Optional[bool] = False):\n    \"\"\"Plot the reflectance spectra corresponding to the associated microfading analyses.\n\n    Parameters\n    ----------\n    stds : list, optional\n         A list of standard variation values respective to each element given in the data parameter, by default []\n\n    spectra : Optional[str], optional\n        Define which spectra to display, by default 'i'\n        Use 'i' for initial spectral, 'f' for final spectra, 'i+f' for initial and final spectra, or 'all' for all the spectra.\n\n    labels : Union[str, list], optional\n        _description_, by default 'default'\n\n    title : str, optional\n        Whether to add a title to the plot, by default None\n\n    fontsize : int, optional\n        Fontsize of the plot (title, ticks, and labels), by default 24\n\n    fontsize_legend : int, optional\n        Fontsize of the legend, by default 26\n\n    wl_range : tuple, optional\n        Define the wavelength range, by default None\n\n    colors : Union[str, list], optional\n        Define the colors of the reflectance curves, by default None\n        When 'sample', the color of each line will be based on srgb values computed from the reflectance values. Alternatively, a single string value can be used to define the color (see matplotlib colour values) or a list of matplotlib colour values can be used. \n\n    lw : Union[int, list], optional\n        Define the width of the plot lines, by default 2\n        It can be a single integer value that will apply to all the curves. Or a list of integers can be used where the number of integer elements should match the number of reflectance curves.\n\n    ls : Union[str, list], optional\n        Define the line style of the plot lines, by default '-'\n        It can be a string ('-', '--', ':', '-.') that will apply to all the curves. Or a list of string can be used where the number of string elements should match the number of reflectance curves.\n\n    save : bool, optional\n        Whether to save the figure, by default False\n\n    path_fig : str, optional\n        Absolute path required to save the figure, by default 'cwd'\n        When 'cwd', it will save the figure in the current working directory.\n\n    derivation : bool, optional\n        Wether to compute and display the first derivative values of the spectra, by default False\n\n    smooth : bool, optional\n        Whether to smooth the reflectance curves, by default False\n\n    smooth_params : list, optional\n        Parameters related to the Savitzky-Golay filter, by default [10,1]\n        Enter a list of two integers where the first value corresponds to the window_length and the second to the polyorder value. \n\n    report : Optional[bool], optional\n        _description_, by default False\n\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n\n    # Retrieve the data\n    data_sp = self.get_data(data='sp')\n    data_sp = [x.set_index(x.columns[0]) for x in data_sp]\n    indices = [x.index for x in data_sp]        \n    columns = [x.columns for x in data_sp] \n\n\n    # Whether to smooth the data\n    if smooth:\n            data_sp = [pd.DataFrame(savgol_filter(x.T, window_length=smooth_params[0], polyorder=smooth_params[1]).T, index=idx, columns=cols) for x,idx,cols in zip(data_sp,indices,columns)]       \n\n    # Reset the index\n    data = [x.reset_index() for x in data_sp]\n\n    # Whether to compute the first derivative\n    if derivation:\n        data = [pd.concat([x.iloc[:,0], pd.DataFrame(np.gradient(x.iloc[:,1:], axis=0))], axis=1) for x in data]\n\n    # Retrieve the metadata\n    info = self.get_metadata()\n    object_info = info.loc['object_type'].values[0]\n    object_technique = info.loc['object_technique'][0]\n    group_nb = info.loc['group'].values[0]\n    group_descriptions = info.loc['group_description'].values\n    group_description = group_descriptions[0]\n\n    ids = [x for x in self.meas_ids if 'BW' not in x]\n    meas_nbs = [x.split('.')[-1] for x in ids]\n\n    # Select which spectra to plot \n    if spectra == 'i':\n        data = [(x.iloc[:,0].values, x.iloc[:,1].values) for x in data]            \n        text = 'Initial spectra'\n\n    elif spectra == 'f':\n        data = [(x.iloc[:,0].values, x.iloc[:,-1].values) for x in data]             \n        text = 'Final spectra'          \n\n    elif spectra == \"i+f\":\n        list_data = [[(x.iloc[:,0].values, x.iloc[:,1].values),(x.iloc[:,0].values, x.iloc[:,-1].values)] for x in data]\n        data = []\n\n        for l1 in list_data:\n            for l2 in l1:\n                data.append(l2)\n\n        ls = ['--', '-'] * len(data)\n        lw = [2,3] * len(data)\n        colors = ['k',colors] * len(data)\n\n        meas_labels = [f'{x}-{y}' for x,y in zip(meas_nbs,group_descriptions)]\n        none_labels = [None] * len(meas_labels)\n        labels = [item for pair in zip(none_labels, meas_labels) for item in pair]\n        text = 'Initial (black dashed lines) and final spectra'\n\n    elif spectra == 'all' :\n\n        data = [\n            [(df.index.values, df[col].values) for col in df.columns]\n            for df in data_sp\n        ]\n        #data = [(x.iloc[:,0].values, x.iloc[:,1:].values) for x in data]            \n        labels = []\n        text = 'All spectra'\n        colors = None\n\n\n    return plotting.spectra(data, stds=[], labels=labels, title=title, fontsize=fontsize, fontsize_legend=fontsize_legend, x_range=wl_range, colors=colors, lw=lw, ls=ls, text=text, save=save, path_fig=path_fig, derivation=derivation)\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.read_files","title":"<code>read_files(sheets=['info', 'CIELAB', 'spectra'])</code>","text":"<p>Read the data files given as argument when defining the instance of the MFT class.</p>"},{"location":"references/#microfading.microfading.MFT.read_files--parameters","title":"Parameters","text":"<p>sheets : Optional[list], optional     Name of the excel sheets to be selected, by default ['info', 'CIELAB', 'spectra']</p>"},{"location":"references/#microfading.microfading.MFT.read_files--returns","title":"Returns","text":"<p>pandas dataframe     It returns of the content of the files where the each column relates to a file.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def read_files(self, sheets:Optional[list] = ['info', 'CIELAB', 'spectra']):\n    \"\"\"Read the data files given as argument when defining the instance of the MFT class.\n\n    Parameters\n    ----------\n    sheets : Optional[list], optional\n        Name of the excel sheets to be selected, by default ['info', 'CIELAB', 'spectra']\n\n    Returns\n    -------\n    pandas dataframe\n        It returns of the content of the files where the each column relates to a file.\n    \"\"\"\n\n    files = []        \n\n    for file in self.files:\n\n        df_info = pd.read_excel(file, sheet_name='info')\n        df_sp = pd.read_excel(file, sheet_name='spectra')\n        df_cl = pd.read_excel(file, sheet_name='CIELAB')\n\n        if 'std' in list(df_sp.iloc[0,:].values):\n            df_sp = pd.read_excel(file, sheet_name='spectra', header=[0,1], index_col=0)\n            df_cl = pd.read_excel(file, sheet_name='CIELAB', header=[0,1])\n\n\n        if sheets == ['info', 'CIELAB', 'spectra']:\n            files.append([df_info, df_cl, df_sp])\n\n        elif sheets == ['info']:\n            files.append([df_info])\n\n        elif sheets == ['CIELAB']:\n            files.append([df_cl])\n\n        elif sheets == ['spectra']:\n            files.append([df_sp])\n\n        elif sheets == ['spectra', 'CIELAB']:\n            files.append([df_sp, df_cl])\n\n        elif sheets == ['CIELAB','spectra']:\n            files.append([df_cl, df_sp])\n\n        elif sheets == ['info','CIELAB']:\n            files.append([df_info, df_cl])\n\n        elif sheets == ['info','spectra']:\n            files.append([df_info, df_sp])\n\n    return files\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.sRGB","title":"<code>sRGB(illuminant='D65', observer='10')</code>","text":"<p>Compute the sRGB values. </p>"},{"location":"references/#microfading.microfading.MFT.sRGB--parameters","title":"Parameters","text":"<p>illuminant : (str, optional)     Reference illuminant ('D65', or 'D50'). by default 'D65'.</p> (str|int, optional) <p>Reference observer in degree ('10' or '2'). by default '10'.</p>"},{"location":"references/#microfading.microfading.MFT.sRGB--returns","title":"Returns","text":"<p>pandas dataframe     It returns the sRGB values inside a dataframe where each column corresponds to a single file.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def sRGB(self, illuminant='D65', observer='10'):\n    \"\"\"Compute the sRGB values. \n\n    Parameters\n    ----------\n    illuminant : (str, optional)  \n        Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n    observer : (str|int, optional)\n        Reference *observer* in degree ('10' or '2'). by default '10'.\n\n    Returns\n    -------\n    pandas dataframe\n        It returns the sRGB values inside a dataframe where each column corresponds to a single file.\n    \"\"\"\n    observer = str(observer)\n\n    illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n    observers = {\n        '10': 'cie_10_1964',\n        '2' : 'cie_2_1931',\n    }\n    cmfs_observers = {\n        '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n        '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n        }\n\n    ccs_ill = colour.CCS_ILLUMINANTS[observers[observer]][illuminant]\n\n    meas_ids = self.meas_ids                \n    df_sp = self.get_data(data='sp')       \n    df_srgb = []\n\n\n    for df, meas_id in zip(df_sp, meas_ids):\n\n        srgb_values = pd.DataFrame(index=['R','G','B']).T           \n\n        for col in df.columns:\n\n            sp = df[col]\n            wl = df.index\n            sd = colour.SpectralDistribution(sp,wl)                \n\n            XYZ = colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]) \n            srgb = colour.XYZ_to_sRGB(XYZ / 100, illuminant=ccs_ill)                          \n            srgb_values = pd.concat([srgb_values, pd.DataFrame(srgb, index=['R','G','B']).T], axis=0)\n            srgb_values.index = np.arange(0,srgb_values.shape[0])\n\n        srgb_values.columns = pd.MultiIndex.from_product([[meas_id], srgb_values.columns])\n        df_srgb.append(srgb_values)\n\n    return pd.concat(df_srgb, axis=1)\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.set_illuminant","title":"<code>set_illuminant(illuminant='D65', observer='10')</code>","text":"<p>Set the illuminant values.</p>"},{"location":"references/#microfading.microfading.MFT.set_illuminant--parameters","title":"Parameters","text":"<p>illuminant : Optional[str], optional     Select the illuminant, by default 'D65'     It can be any value within the following list: ['A', 'B', 'C', 'D50', 'D55', 'D60', 'D65', 'D75', 'E', 'FL1', 'FL2', 'FL3', 'FL4', 'FL5', 'FL6', 'FL7', 'FL8', 'FL9', 'FL10', 'FL11', 'FL12', 'FL3.1', 'FL3.2', 'FL3.3', 'FL3.4', 'FL3.5', 'FL3.6', 'FL3.7', 'FL3.8', 'FL3.9', 'FL3.10', 'FL3.11', 'FL3.12', 'FL3.13', 'FL3.14', 'FL3.15', 'HP1', 'HP2', 'HP3', 'HP4', 'HP5', 'LED-B1', 'LED-B2', 'LED-B3', 'LED-B4', 'LED-B5', 'LED-BH1', 'LED-RGB1', 'LED-V1', 'LED-V2', 'ID65', 'ID50', 'ISO 7589 Photographic Daylight', 'ISO 7589 Sensitometric Daylight', 'ISO 7589 Studio Tungsten', 'ISO 7589 Sensitometric Studio Tungsten', 'ISO 7589 Photoflood', 'ISO 7589 Sensitometric Photoflood', 'ISO 7589 Sensitometric Printer']</p> Optional[str], optional <p>Standard observer in degree, by default '10' It can be either '2' or '10'</p>"},{"location":"references/#microfading.microfading.MFT.set_illuminant--returns","title":"Returns","text":"<p>tuple     It returns a tuple with two set of values: the chromaticity coordinates of the illuminants (CCS) and the spectral distribution of the illuminants (SDS).</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def set_illuminant(self, illuminant:Optional[str] = 'D65', observer:Optional[str] = '10'):\n    \"\"\"Set the illuminant values.\n\n    Parameters\n    ----------\n    illuminant : Optional[str], optional\n        Select the illuminant, by default 'D65'\n        It can be any value within the following list: ['A', 'B', 'C', 'D50', 'D55', 'D60', 'D65', 'D75', 'E', 'FL1', 'FL2', 'FL3', 'FL4', 'FL5', 'FL6', 'FL7', 'FL8', 'FL9', 'FL10', 'FL11', 'FL12', 'FL3.1', 'FL3.2', 'FL3.3', 'FL3.4', 'FL3.5', 'FL3.6', 'FL3.7', 'FL3.8', 'FL3.9', 'FL3.10', 'FL3.11', 'FL3.12', 'FL3.13', 'FL3.14', 'FL3.15', 'HP1', 'HP2', 'HP3', 'HP4', 'HP5', 'LED-B1', 'LED-B2', 'LED-B3', 'LED-B4', 'LED-B5', 'LED-BH1', 'LED-RGB1', 'LED-V1', 'LED-V2', 'ID65', 'ID50', 'ISO 7589 Photographic Daylight', 'ISO 7589 Sensitometric Daylight', 'ISO 7589 Studio Tungsten', 'ISO 7589 Sensitometric Studio Tungsten', 'ISO 7589 Photoflood', 'ISO 7589 Sensitometric Photoflood', 'ISO 7589 Sensitometric Printer']\n\n    observer : Optional[str], optional\n        Standard observer in degree, by default '10'\n        It can be either '2' or '10'\n\n    Returns\n    -------\n    tuple\n        It returns a tuple with two set of values: the chromaticity coordinates of the illuminants (CCS) and the spectral distribution of the illuminants (SDS).\n    \"\"\"\n\n    observers = {\n        '10': \"cie_10_1964\",\n        '2' : \"cie_2_1931\"\n    }\n\n    CCS = colour.CCS_ILLUMINANTS[observers[observer]][illuminant]\n    SDS = colour.SDS_ILLUMINANTS[illuminant]\n\n    return CCS, SDS\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.set_observer","title":"<code>set_observer(observer='10')</code>","text":"<p>Set the observer.</p>"},{"location":"references/#microfading.microfading.MFT.set_observer--parameters","title":"Parameters","text":"<p>observer : Optional[str], optional     Standard observer in degree, by default '10'     It can be either '2' or '10'</p>"},{"location":"references/#microfading.microfading.MFT.set_observer--returns","title":"Returns","text":"<pre><code>Returns the x_bar,  y_bar, z_bar spectra between 360 and 830 nm.\n</code></pre> Source code in <code>src/microfading/microfading.py</code> <pre><code>def set_observer(self, observer:Optional[str] = '10'):\n    \"\"\"Set the observer.\n\n    Parameters\n    ----------\n    observer : Optional[str], optional\n        Standard observer in degree, by default '10'\n        It can be either '2' or '10'\n\n    Returns\n    -------        \n        Returns the x_bar,  y_bar, z_bar spectra between 360 and 830 nm.\n    \"\"\"\n\n    observers = {\n        '10': \"CIE 1964 10 Degree Standard Observer\",\n        '2' : \"CIE 1931 2 Degree Standard Observer\"\n    }\n\n    return colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[observers[observer]]\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.sp_derivation","title":"<code>sp_derivation()</code>","text":"<p>Compute the first derivative values of reflectance spectra.</p>"},{"location":"references/#microfading.microfading.MFT.sp_derivation--returns","title":"Returns","text":"<p>a list of pandas dataframes     It returns the first derivative values of the reflectance spectra inside dataframes where each column corresponds to a single spectra.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def sp_derivation(self):\n    \"\"\"Compute the first derivative values of reflectance spectra.\n\n    Returns\n    -------\n    a list of pandas dataframes\n        It returns the first derivative values of the reflectance spectra inside dataframes where each column corresponds to a single spectra.\n    \"\"\"\n\n    sp = self.get_data(data='sp')                    \n\n    sp_derivation = [pd.DataFrame(pd.concat([pd.DataFrame(np.gradient(x.iloc[:,:], axis=0), index=pd.Series(x.index), columns=x.columns)], axis=1),index=pd.Series(x.index), columns=x.columns) for x in sp]\n\n    return sp_derivation\n</code></pre>"},{"location":"references/#microfading.microfading.MFT.xy","title":"<code>xy(illuminant='D65', observer='10')</code>","text":"<p>Compute the xy values. </p>"},{"location":"references/#microfading.microfading.MFT.xy--parameters","title":"Parameters","text":"<p>illuminant : (str, optional)     Reference illuminant ('D65', or 'D50'). by default 'D65'.</p> (str|int, optional) <p>Reference observer in degree ('10' or '2'). by default '10'.</p>"},{"location":"references/#microfading.microfading.MFT.xy--returns","title":"Returns","text":"<p>pandas dataframe     It returns the xy values inside a dataframe where each column corresponds to a single file.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def xy(self, illuminant:Optional[str] = 'D65', observer:Union[str, int] = '10'):\n    \"\"\"Compute the xy values. \n\n    Parameters\n    ----------\n    illuminant : (str, optional)  \n        Reference *illuminant* ('D65', or 'D50'). by default 'D65'.\n\n    observer : (str|int, optional)\n        Reference *observer* in degree ('10' or '2'). by default '10'.\n\n    Returns\n    -------\n    pandas dataframe\n        It returns the xy values inside a dataframe where each column corresponds to a single file.\n    \"\"\"\n\n\n    observer = str(observer)\n\n    illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n    observers = {\n        '10': 'cie_10_1964',\n        '2' : 'cie_2_1931',\n    }\n    cmfs_observers = {\n        '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n        '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n        }\n\n    meas_ids = self.meas_ids                \n    df_sp = self.get_data(data='sp')       \n    df_xy = []\n\n\n    for df, meas_id in zip(df_sp, meas_ids):\n\n        xy_values = pd.DataFrame(index=['x','y']).T           \n\n        for col in df.columns:\n\n            sp = df[col]\n            wl = df.index\n            sd = colour.SpectralDistribution(sp,wl)                \n\n            XYZ = np.round(colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]),3)\n            xy = np.round(colour.XYZ_to_xy(XYZ),4)\n            xy_values = pd.concat([xy_values, pd.DataFrame(xy, index=['x','y']).T], axis=0)\n            xy_values.index = np.arange(0,xy_values.shape[0])\n\n        xy_values.columns = pd.MultiIndex.from_product([[meas_id], xy_values.columns])\n        df_xy.append(xy_values)\n\n    return pd.concat(df_xy, axis=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    observer = str(observer)\n\n    illuminants = {'D65':colour.SDS_ILLUMINANTS['D65'], 'D50':colour.SDS_ILLUMINANTS['D50']}\n    observers = {\n        '10': 'cie_10_1964',\n        '2' : 'cie_2_1931',\n    }\n    cmfs_observers = {\n        '10': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1964 10 Degree Standard Observer\"],\n        '2': colour.colorimetry.MSDS_CMFS_STANDARD_OBSERVER[\"CIE 1931 2 Degree Standard Observer\"] \n        }\n\n    df_xy = pd.DataFrame(index=pd.Series(['x','y']))\n    df_sp = self.get_data(data='sp')\n    wl = df_sp.index\n\n    for col in df_sp.columns:\n        sp = df_sp[col]\n        sd = colour.SpectralDistribution(sp,wl)\n\n        XYZ = colour.sd_to_XYZ(sd,cmfs_observers[observer], illuminant=illuminants[illuminant]) \n        xy = np.round(colour.XYZ_to_xy(XYZ),4)\n\n        df_xy[col] = xy\n\n    return df_xy\n</code></pre>"},{"location":"references/#microfading.microfading.create_DB","title":"<code>create_DB(folder)</code>","text":"<p>Create two empty databases, one for the projects and one for the objects.</p>"},{"location":"references/#microfading.microfading.create_DB--parameters","title":"Parameters","text":"<p>folder : str     Absolute path of the folder where the databases will be stored.</p>"},{"location":"references/#microfading.microfading.create_DB--returns","title":"Returns","text":"<pre><code>It creates the two empty databases as csv file (DB_projects.csv and DB_objects.csv) in the folder given as input.\n</code></pre> Source code in <code>src/microfading/microfading.py</code> <pre><code>def create_DB(folder:str):\n    \"\"\"Create two empty databases, one for the projects and one for the objects.\n\n    Parameters\n    ----------\n    folder : str\n        Absolute path of the folder where the databases will be stored.\n\n    Returns\n    -------\n        It creates the two empty databases as csv file (DB_projects.csv and DB_objects.csv) in the folder given as input.\n    \"\"\"\n\n    DB = databases.DB()\n    DB.create_db(folder_path=folder)\n</code></pre>"},{"location":"references/#microfading.microfading.folder_DB","title":"<code>folder_DB()</code>","text":"<p>Retrieve the absolute path of the folder where the databases are located.</p>"},{"location":"references/#microfading.microfading.folder_DB--returns","title":"Returns","text":"<p>string or None</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def folder_DB():\n    \"\"\"Retrieve the absolute path of the folder where the databases are located.\n\n    Returns\n    -------\n    string or None        \n    \"\"\"\n\n    DB = databases.DB()    \n\n    if 'DB_projects.csv' in os.listdir(DB.folder_db) and 'DB_objects.csv' in os.listdir(DB.folder_db):\n\n        print(f'DB_projects.csv and DB_objects.csv files can be found in the following folder: {DB.folder_db}')    \n        return DB.folder_db       \n\n    else:\n        print('Databases have not been created or have been deleted. Please, create databases by running the function \"create_DB\" from the microfading package.')\n        return None\n</code></pre>"},{"location":"references/#microfading.microfading.get_datasets","title":"<code>get_datasets(rawfiles=False, BWS=True, stdev=False)</code>","text":"<p>Retrieve exemples of dataset files. These files are meant to give the users the possibility to test the MFT class and its functions.  </p>"},{"location":"references/#microfading.microfading.get_datasets--parameters","title":"Parameters","text":"<p>rawfiles : Optional[bool], optional     Whether to get rawdata files, by default False     The raw files were obtained from microfading analyses performed with the Fotonowy device and consist of four files per analysis.</p> Optional[bool], optional <p>Whether to include the microfading measurements on blue wool standards (BWS), by default True</p> Optional[bool], optional <p>Whether to have microfading measurements wiht standard deviation values, by default False</p>"},{"location":"references/#microfading.microfading.get_datasets--returns","title":"Returns","text":"<p>list     It returns a list of strings, where each string corresponds the absolute path of a microfading measurement excel file. Subsequently, one can use the list as input for the MFT class.</p> Source code in <code>src/microfading/microfading.py</code> <pre><code>def get_datasets(rawfiles:Optional[bool] = False, BWS:Optional[bool] = True, stdev:Optional[bool] = False):\n    \"\"\"Retrieve exemples of dataset files. These files are meant to give the users the possibility to test the MFT class and its functions.  \n\n    Parameters\n    ----------\n    rawfiles : Optional[bool], optional\n        Whether to get rawdata files, by default False\n        The raw files were obtained from microfading analyses performed with the Fotonowy device and consist of four files per analysis.\n\n    BWS : Optional[bool], optional\n        Whether to include the microfading measurements on blue wool standards (BWS), by default True\n\n    stdev : Optional[bool], optional\n        Whether to have microfading measurements wiht standard deviation values, by default False\n\n    Returns\n    -------\n    list\n        It returns a list of strings, where each string corresponds the absolute path of a microfading measurement excel file. Subsequently, one can use the list as input for the MFT class. \n    \"\"\"\n\n    if stdev:\n        data_files = [\n            '2024-144_MF.BWS0024.G01_avg_BW1_model_2024-07-30_MFT2.xlsx',\n            '2024-144_MF.BWS0025.G01_avg_BW2_model_2024-08-02_MFT2.xlsx',\n            '2024-144_MF.BWS0026.G01_avg_BW3_model_2024-08-07_MFT2.xlsx',\n            '2024-144_MF.dayflower4.G01_avg_0h_model_2024-07-30_MFT2.xlsx',\n            '2024-144_MF.indigo3.G01_avg_0h_model_2024-08-02_MFT2.xlsx',\n        ]\n\n    else:\n        data_files = [\n            '2024-144_MF.BWS0026.04_G02_BW3_model_2024-08-02_MFT1.xlsx',\n            '2024-144_MF.BWS0025.04_G02_BW2_model_2024-08-02_MFT1.xlsx',\n            '2024-144_MF.BWS0024.04_G02_BW1_model_2024-08-02_MFT1.xlsx',\n            '2024-144_MF.yellowwood.01_G01_yellow_model_2024-08-01_MFT1.xlsx',\n            '2024-144_MF.vermillon.01_G01_red_model_2024-07-31_MFT1.xlsx',\n        ]\n\n    if rawfiles:\n        data_files = [\n            '2024-8200 P-001 G01 uncleaned_01-spect_convert.txt',\n            '2024-8200 P-001 G01 uncleaned_01-spect.txt',\n            '2024-8200 P-001 G01 uncleaned_01.txt',\n            '2024-8200 P-001 G01 uncleaned_01.rfc',\n            '2024-144 BWS0024 G01 BW1_01-spect_convert.txt',\n            '2024-144 BWS0024 G01 BW1_01-spect.txt',\n            '2024-144 BWS0024 G01 BW1_01.txt',\n            '2024-144 BWS0024 G01 BW1_01.rfc',\n        ]\n\n    if BWS == False:\n        data_files = [x for x in data_files if 'BWS' not in x]\n\n\n\n    # Get the paths to the data files within the package\n    file_paths = []\n    for file_name in data_files:\n\n        with pkg_resources.path('microfading.datasets', file_name) as data_file:\n             file_paths.append(data_file)\n\n    return file_paths\n</code></pre>"},{"location":"retrieve-test-datasets/","title":"Retrieve test datasets","text":"<p>This page describes how to retrieve examples of interim files that can subsequently be used to explore the microfading package. </p> <p>First, open a jupyter notebook, import the microfading package and then retrieve the paths using the <code>get_datasets()</code> function, as illustrated below. The <code>get_datasets()</code> function has three optional parameters that allows you to filter the files:</p> <ul> <li><code>rawfiles</code> (True or False) : you can decide to retrieve rawdata files or interim files. The former will enable you to run the <code>process_rawdata()</code> function, while the latter will allow you to directly create an <code>MFT</code> class instance and explore the functionalities of the package.</li> <li><code>BWS</code> (True or False) : you can decide to include or exclude measurements performed on blue wool samples.</li> <li><code>stdev</code> (True or False) : you can decide to retrieve file with or without standard deviation values. This parameter only applies for the interim files.</li> </ul> <pre><code>import microfading as mf\n</code></pre> <pre><code>\n</code></pre> <pre><code># by default rawfiles=False, BWS=True, stdev=False\nds = mf.get_datasets()\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0026.04_G02_BW3_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0025.04_G02_BW2_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.BWS0024.04_G02_BW1_model_2024-08-02_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.yellowwood.01_G01_yellow_model_2024-08-01_MFT1.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.vermillon.01_G01_red_model_2024-07-31_MFT1.xlsx')]\n</code></pre> <pre><code># retrieve all the rawfiles\nds = mf.get_datasets(rawfiles=True)\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.rfc'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144 BWS0024 G01 BW1_01.rfc')]\n</code></pre> <pre><code># excluded the rawfiles performed on blue wool samples\nds = mf.get_datasets(rawfiles=True, BWS=False)\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect_convert.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01-spect.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.txt'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-8200 P-001 G01 uncleaned_01.rfc')]\n</code></pre> <pre><code># retrieved the interim files with standard devivation values\nds = mf.get_datasets(rawfiles=False, BWS=False, stdev=True)\nds\n</code></pre> <pre><code>[PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.dayflower4.G01_avg_0h_model_2024-07-30_MFT2.xlsx'),\n PosixPath('/home/gpatin/Documents/test/venv/lib/python3.11/site-packages/microfading/datasets/2024-144_MF.indigo3.G01_avg_0h_model_2024-08-02_MFT2.xlsx')]\n</code></pre>"}]}